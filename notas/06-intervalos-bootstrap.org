#+TITLE: EST-24107: Simulación
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Intervalos de remuestreo~
#+STARTUP: showall
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/06-intervalos-bootstrap.pdf
:END:
#+PROPERTY: header-args:R :session intervalos :exports both :results output org :tangle ../rscript/06-intervalos-bootstrap.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc noexport 

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Otoño, 2022 | /Bootstrap/.\\
*Objetivo*: Que veremos.\\
*Lectura recomendada*: Referencia.
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)

  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 5)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src

* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#error-estándar-bootstrap-e-intervalos-normales][Error estándar bootstrap e intervalos normales]]
  - [[#definición][Definición:]]
- [[#inventarios-de-casas-vendidas][Inventarios de casas vendidas]]
  - [[#nota][Nota:]]
- [[#calibración-de-intervalos-de-confianza][Calibración de intervalos de confianza]]
  - [[#observación][Observación:]]
- [[#interpretación-intervalos-de-confianza][Interpretación intervalos de confianza]]
- [[#intervalos-bootstrap-de-percentiles][Intervalos bootstrap de percentiles]]
  - [[#definición][Definición:]]
  - [[#ejercicio][Ejercicio:]]
- [[#conclusiones-y-observaciones][Conclusiones y observaciones]]
:END:


*  Error estándar /bootstrap/ e intervalos normales

Ahora podemos construir nuestra primera versión de intervalos de confianza
basados en la distribución /bootstrap/.

- Supongamos que queremos estimar una cantidad poblacional $\theta$ con una
  estadística $\hat{\theta} = t(X_1,\ldots, X_n)$, donde $X_1,\ldots, X_n$ es
  una muestra independiente e idénticamente distribuida de la población.

- Suponemos además que la distribución muestral de $\hat{\theta}$ es
  aproximadamente normal (el teorema central del límite aplica), y está centrada
  en el verdadero valor poblacional $\theta$.

Ahora queremos construir un intervalo que tenga probabilidad $95\%$ de cubrir al
valor poblacional $\theta$. Tenemos que
\begin{align}
P(-2\mathsf{ee}(\hat{\theta}) < \hat{\theta} - \theta < 2\mathsf{ee}(\hat{\theta})) \approx 0.95\,,
\end{align}
por las propiedades de la distribución normal ($P(-2\sigma < X -\mu <
2\sigma)\approx 0.95$ si $X$ es normal con media $\mu$ y desviación estándar
$\sigma$). Entonces
\begin{align}
P(\hat{\theta} - 2\mathsf{ee}(\hat{\theta}) < \theta < \hat{\theta} + 2\mathsf{ee}(\hat{\theta})) \approx 0.95\,.
\end{align}
Es decir, la probabilidad de que el verdadero valor poblacional $\theta$ esté en
el intervalo $$[\hat{\theta} - 2\mathsf{ee}(\hat{\theta}), \hat{\theta} +
2\mathsf{ee}(\hat{\theta})]$$ es cercano a 0.95. En este intervalo no conocemos
el error estándar (es la desviación estándar de la distribución de muestreo de
$\hat{\theta}$), y aquí es donde entre la distribución /bootstrap/, que aproxima
la distribución de muestreo (en términos de varianza). Lo estimamos con
\begin{align}
\hat{\mathsf{ee}}_{\mathsf{boot}}(\hat{\theta})\,,
\end{align}
que es la desviación estándar de la *distribución /bootstrap/*.

*** ~Definición~:
El *error estándar /bootstrap/* $\hat{\mathsf{ee}}_{\textrm{boot}}(\hat{\theta})$ se
define como la desviación estándar de la distribución bootstrap de $\theta$. El
*intervalo de confianza normal /bootstrap/* al $95\%$ está dado por
\begin{align}
[\hat{\theta} -
2\hat{\mathsf{ee}}_{\mathsf{boot}}(\hat{\theta}), \hat{\theta} + 2\hat{\mathsf{ee}}_{\mathsf{boot}}(\hat{\theta})]\,.
\end{align}
  
Nótese que hay varias cosas qué checar aquí: que el teorema central del límite aplica y
que la distribución de muestreo de nuestro estimador está centrado en el valor verdadero.
Esto en algunos casos se puede demostrar usando la teoría, pero más abajo veremos
comprobaciones empíricas.

\newpage

** Ejemplo

Consideremos la estimación que hicimos de el procentaje de tomadores de té que
toma té negro:

#+begin_src R :exports both :results org 
  ## paso 1: define el estimador
  calc_estimador <- function(datos){
    prop_negro <- datos |>
      mutate(negro = ifelse(Tea == "black", 1, 0)) |>
      summarise(prop_negro = mean(negro), n = length(negro)) |>
      pull(prop_negro)
    prop_negro
  }
  prop_hat <- calc_estimador(te)
  prop_hat |> round(4)
#+END_SRC

#+RESULTS:
#+begin_src org
[1] 0.2467
#+end_src

Podemos graficar su distribución bootstrap ---la cual simulamos arriba---.

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/distirbucion-bs-te-negro.jpeg :exports results :results output graphics file :eval never
  g_hist <- ggplot(prop_negro_tbl, aes(x = prop_negro)) + geom_histogram(bins = 15) + sin_lineas
  g_qq_normal <- ggplot(prop_negro_tbl, aes(sample = prop_negro)) +
    geom_qq() + geom_qq_line(colour = "red") + sin_lineas
  g_hist + g_qq_normal
#+end_src

#+RESULTS:
[[file:../images/distirbucion-bs-te-negro.jpeg]]

Y notamos que la distribución /bootstrap/ es aproximadamente normal. 
Adicionalmente, vemos que el sesgo tiene un valor estimado de:

#+begin_src R :exports both :results org 
  media_boot <- prop_negro_tbl |> pull(prop_negro) |> mean()
  media_boot - prop_hat
#+end_src

#+RESULTS:
#+begin_src org
[1] -0.00011667
#+end_src

De esta forma, hemos verificado que:

- La distribución /bootstrap/ es aproximadamente normal (ver gráfica de cuantiles normales); 
- La distribución /bootstrap/ es aproximadamente insesgada.

Lo cual nos lleva a construir intervalos de confianza basados en la distribución
normal. Estimamos el error estándar con la desviación estándar de la
distribución /bootstrap/

#+begin_src R :exports both :results org 
ee_boot <- prop_negro_tbl |> pull(prop_negro) |> sd()
ee_boot
#+end_src

#+RESULTS:
#+begin_src org
[1] 0.024178
#+end_src

y construimos un intervalo de confianza del $95\%$:

#+begin_src R :exports both :results org 
  intervalo_95 <- c(inf = prop_hat - 2 * ee_boot,
                    centro = prop_hat,
                    sup = prop_hat + 2 * ee_boot)
  intervalo_95 |> round(3)
#+end_src

#+RESULTS:
#+begin_src org
   inf centro    sup 
 0.198  0.247  0.295
#+end_src

Este intervalo tiene probabilidad del $95\%$ de capturar al verdadero poblacional.

* Inventarios de casas vendidas 

Ahora consideremos el problema de estimar el total del valor de las casas
vendidas en un periodo. Tenemos una muestra de tamaño $n=150$:

#+begin_src R :exports code :results none 
  ## muestra original
  set.seed(121)
  muestra_casas <- sample_n(poblacion_casas, size = 150)
  ## paso 1: define el estimador
  calc_estimador_casas <- function(datos){
    N <- nrow(poblacion_casas)
    n <- nrow(datos)
    total_muestra <- sum(datos$precio_miles)
    estimador_total <- (N / n) * total_muestra
    estimador_total
  }
#+end_src

#+begin_src R :exports code :results none 
  ## paso 2: define el proceso de remuestreo
  muestra_boot <- function(datos){
    ## tomar muestra con reemplazo del mismo tamaño
    sample_n(datos, size = nrow(datos), replace = TRUE)
  }
#+end_src

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-bootstrap-intervalos.jpeg :exports results :results output graphics file :eval never
  ## paso 3: remuestrea y calcula el estimador
  totales_boot <- map_dbl(1:5000,  ~ calc_estimador_casas(muestra_boot(muestra_casas))) %>% 
    tibble(total_boot = .)
  ## paso 4: examina la distribución bootstrap
  g_hist <- totales_boot %>% 
    ggplot(aes(x = total_boot)) +
    geom_histogram() + sin_lineas +
    geom_vline(xintercept = quantile(totales_boot$total_boot, 0.975), colour = "gray") +
    geom_vline(xintercept = quantile(totales_boot$total_boot, 0.025), colour = "gray")
  g_qq <- totales_boot %>%
    ggplot(aes(sample = total_boot)) +
    geom_qq() + geom_qq_line(colour = "red") +
    geom_hline(yintercept = quantile(totales_boot$total_boot, 0.975), colour = "gray") +
    geom_hline(yintercept = quantile(totales_boot$total_boot, 0.025), colour = "gray") +
    sin_lineas
  g_hist + g_qq
#+end_src

#+RESULTS:
[[file:../images/casas-bootstrap-intervalos.jpeg]]

En este caso, distribución de muestreo presenta cierta asimetría, pero la
desviación no es grande. En la parte central la aproximación normal es
razonable. Procedemos a checar sesgo

#+begin_src R :exports both :results org 
  total_est <- calc_estimador_casas(muestra_casas)
  sesgo <- mean(totales_boot$total_boot) - total_est
  sesgo
#+end_src

#+RESULTS:
#+begin_src org
[1] 110.1
#+end_src

Este número puede parecer grande, pero sí calculamos la desviación relativa
con respecto al estimador vemos que es chico en la escala de la distribución 
/bootstrap/:

#+begin_src R :exports both :results org 
  sesgo_relativo <- sesgo / total_est
  sesgo_relativo
#+end_src

#+RESULTS:
#+begin_src org
[1] 0.0005054
#+end_src

De forma que procedemos a construir intervalos de confianza como sigue :
#+begin_src R :exports both :results org 
  ee_boot <- sd(totales_boot$total_boot)
  c(inf = total_est - 2*ee_boot, centro = total_est, sup = total_est + 2*ee_boot)  
#+end_src

#+RESULTS:
#+begin_src org
   inf centro    sup 
203367 217832 232297
#+end_src

Que está en miles de dólares. En millones de dólares, este intervalo es:

#+begin_src R :exports both :results org 
  intervalo_total <- c(inf = total_est - 2*ee_boot,
                       centro = total_est,
                       sup = total_est + 2*ee_boot) / 1000
  intervalo_total |> round(5)
#+end_src

#+RESULTS:
#+begin_src org
   inf centro    sup 
203.37 217.83 232.30
#+end_src

*** ~Nota~:
En este ejemplo mostraremos una alternativa de intervalos de confianza que es
más apropiado cuando observamos asimetría. Sin embargo, primero tendremos que
hablar de dos conceptos clave con respecto a intervalos de confianza:
calibración e interpretación.

* Calibración de intervalos de confianza 

¿Cómo sabemos que nuestros intervalos de confianza del $95\%$ nominal 
tienen cobertura real de $95\%$? Es decir, tenemos que checar:

- El procedimiento para construir intervalos debe dar intervalos tales que el
  valor poblacional está en el intervalo de confianza para 95% de las muestras.

Como solo tenemos una muestra, la calibración depende de argumentos teóricos o
estudios de simulación previos. Para nuestro ejemplo de casas tenemos la
población, así que podemos checar qué cobertura real tienen los intervalos
normales:

#+begin_src R :exports none :results none :eval never :tangle no
  simular_intervalos <- function(rep, size = 150){
    muestra_casas <- sample_n(poblacion_casas, size = size)
    N <- nrow(poblacion_casas)
    n <- nrow(muestra_casas)
    total_est <- (N / n) * sum(muestra_casas$precio_miles)
    ## paso 1: define el estimador
    calc_estimador_casas <- function(datos){
      total_muestra <- sum(datos$precio_miles)
      estimador_total <- (N / n) * total_muestra
      estimador_total
    }
    ## paso 2: define el proceso de remuestreo
    muestra_boot <- function(datos){
      ## tomar muestra con reemplazo del mismo tamaño
      sample_n(datos, size = nrow(datos), replace = TRUE)
    }
    ## paso 3: remuestrea y calcula el estimador
    totales_boot <- map_dbl(1:2000,  ~ calc_estimador_casas(muestra_boot(muestra_casas))) %>% 
      tibble(total_boot = .) %>%
      summarise(ee_boot = sd(total_boot)) %>% 
      mutate(inf = total_est - 2*ee_boot, sup = total_est + 2*ee_boot) %>% 
      mutate(rep = rep)
    totales_boot
  }
  ## Para recrear, correr:
  sims_intervalos <- map(1:100, ~ simular_intervalos(rep = .x))
  write_rds(sims_intervalos, "cache/sims_intervalos.rds")
#+end_src

#+begin_src R :exports none :results none 
  ## Para usar resultados en cache:
  sims_intervalos <- read_rds("cache/sims_intervalos.rds")
#+end_src


#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-estimacion-intervalos.jpeg :exports results :results output graphics file
  total <- sum(poblacion_casas$precio_miles)
  sims_tbl <- sims_intervalos |>
    bind_rows |>
    mutate(cubre = inf < total & total < sup) 
  ggplot(sims_tbl, aes(x = rep)) +
    geom_hline(yintercept = total, colour = "red") +
    geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre)) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/casas-estimacion-intervaloes.jpeg]]

La cobertura para estos 100 intervalos simulados da

#+begin_src R :exports both :results org 
  total <- sum(poblacion_casas$precio_miles)
  sims_tbl %>% 
    summarise(cobertura = mean(cubre))  
#+end_src

que es *consistente* con una cobertura real del $95\%$ (¿qué significa
``consistente''? ¿Cómo puedes checarlo con el /bootstrap/?)

*** ~Observación~:
En este caso teníamos la población real, y pudimos verificar la cobertura de
nuestros intervalos. En general no la tenemos. Estos ejercicios de simulación se
pueden hacer con poblaciones sintéticas que se generen con las características
que creemos va a tener nuestra población (por ejemplo, sesgo, colas largas,
etc.).

#+BEGIN_NOTES
En general, no importa qué tipo de estimadores o intervalos de confianza usemos,
requerimos checar la calibración. Esto puede hacerse con ejercicios de
simulación con poblaciones sintéticas y tanto los procedimientos de muestreo
como los tamaños de muestra que nos interesa usar.
#+END_NOTES

Verificar la cobertura de nuestros intervalos de confianza por medio simulación está
bien estudiado para algunos casos. Por ejemplo, cuando trabajamos con estimaciones para 
poblaciones teóricas. En general sabemos que los procedimientos funcionan bien en casos: 
- con distribuciones simétricas que tengan colas no muy largas; 
- estimación de proporciones donde no tratamos con casos raros o casos seguros
  (probabilidades cercanas a 0 o 1).

* Interpretación intervalos de confianza 

Como hemos visto, ``intervalo de confianza'' (de $90\%$ de confianza, por ejemplo)
es un término *frecuentista*, que significa:

- *Cada muestra produce un intervalo distinto*. Para el $90\%$ de las muestras
  posibles, el intervalo cubre al valor poblacional.
- La afirmación es *sobre el intervalo y el mecanismo para construirlo.*
- Así que con *alta probabilidad*, el intervalo contiene el valor poblacional.
- Intervalos más anchos nos dan más incertidumbre acerca de dónde está el
  verdadero valor poblacional (y al revés para intervalos más angostos).

Existen también ``intervalos de credibilidad'' (de $90\%$ de probabilidad, por
ejemplo), que se interpetan de forma *bayesiana*:

- Con $90\%$ de probabilidad (relativamente alta), creemos que el valor
  poblacional está dentro del intervalo de credibilidad.

Esta última interpretación es más natural. Obsérvese que para hablar de
intervalos de confianza frecuentista tenemos que decir:

- Este intervalo particular cubre o no al verdadero valor, pero nuestro
  procedimiento produce intervalos que contiene el verdadero valor para el $90\%$ de las muestras. 
- Esta es una interpretación relativamente débil, y muchos intervalos poco útiles pueden satisfacerla.
- La interpretación bayesiana es más natural porque expresa más claramente
  incertidumbre acerca del valor poblacional.

Sin embargo,

- La interpretación frecuentista nos da maneras empíricas de probar si los
  intervalos de confianza están bien calibrados o no: es un mínimo que
  ``intervalos del $90\%$'' deberían satisfacer.

Así que tomamos el punto de vista bayesiano en la intepretación, pero buscamos
que nuestros intervalos cumplan o aproximen bien garantías frecuentistas
(discutimos esto más adelante). Los intervalos que producimos en esta sección
pueden interpretarse de las dos maneras.

* Intervalos /bootstrap/ de percentiles 

Retomemos nuestro ejemplo del valor total del precio de las casas. A través de
remuestras bootstrap hemos verificado gráficamente que la distribución de
remuestreo es *ligeramente* asimétrica (ver la figura de abajo). 

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-histograma.jpeg :exports results :results output graphics file :eval never
  g_hist2 <- totales_boot|>
    ggplot(aes(x = total_boot)) +
    geom_histogram(aes(y = ..density..)) + 
    stat_function(fun = dnorm, args = list(mean = total_est, sd = ee_boot),
                  color = 'red', lty = 2) +
    sin_lineas

  g_hist2 + g_qq
#+end_src

#+RESULTS:
[[file:../images/casas-histograma.jpeg]]

Anteriormente hemos calculado intervalos de confianza basados en supuestos
normales por medio del error éstandar. Este intervalo está dado por

#+begin_src R :exports both :results org 
  intervalo_total %>% round(1)  
#+end_src

#+RESULTS:
#+begin_src org
   inf centro    sup 
 203.4  217.8  232.3
#+end_src

y por construcción sabemos que es simétrico con respecto al valor estimado, pero 
como podemos ver la distribución de muestreo no es simétrica, lo cual podemos
confirmar por ejemplo calculando el porcentaje de muestras bootstrap que caen
por arriba y por debajo del intervalo construido:

#+begin_src R :exports both :results org 
  totales_boot |> 
    mutate(upper = total_boot >= max(intervalo_total * 1000), 
           lower = total_boot <= min(intervalo_total * 1000)) |>
    summarise(prop_inf = mean(lower), 
              prop_sup = mean(upper))
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 2
  prop_inf prop_sup
     <dbl>    <dbl>
1   0.0192    0.026
#+end_src

los cuales se han calculado como el porcentaje de medias /bootstrap/ por debajo
(arriba) de la cota inferior (superior), y vemos que no coinciden con el nivel de 
confianza preestablecido ($2.5\%$ para cada extremo).

Otra opción común que se usa específicamente cuando la distribución bootstrap 
no es muy cercana a la normal son los intervalos de percentiles /bootstrap/:

*** ~Definición~:
El *intervalo de percentiles /bootstrap/* al $95\%$ de confianza está dado por
\begin{align}
[q_{0.025}, q_{0.975}]\,,
\end{align}
donde $q_f$ es el percentil $f$ de la distribución /bootstrap/.


Otros intervalos comunes son el de $80\%$ o $90\%$ de confianza, por ejemplo,
que corresponden a $[q_{0.10}, q_{0.90}]$ y $[q_{0.05}, q_{0.95}]$. *Ojo*:
intervalos de confianza muy alta (por ejemplo $99.5\%$) pueden tener mala
calibración o ser muy variables en su longitud pues dependen del comportamiento
en las colas de la distribución.

Para el ejemplo de las casas, calcularíamos simplemente

#+begin_src R :exports both :results org 
  intervalo_95 <- totales_boot |> pull(total_boot) %>%
    quantile(., probs = c(0.025, 0.50, 0.975)) / 1000
  (intervalo_95) %>% round(1)
#+end_src

#+RESULTS:
#+begin_src org
 2.5%   50% 97.5% 
204.3 217.8 232.5
#+end_src
que está en millones de dólares. Nótese que es similar al intervalo de error estándar.

Otro punto interesante sobre los intervalos /bootstrap/ de percentiles es que
lidian naturalmente con la asímetría de la distribución bootstrap. Ilustramos
esto con la distancia de las extremos del intervalo con respecto a la media:

#+begin_src R :exports both :results org 
  abs(intervalo_95 - total_est/1000)  
#+end_src

#+RESULTS:
#+begin_src org
      2.5%        50%      97.5% 
13.5391163  0.0033367 14.6467418
#+end_src

Los intervalos de confianza nos permiten presentar un rango de valores posibles
para el parámetro de interés. Esto es una notable diferencia con respecto a
presentar sólo un candidato como estimador. Nuestra fuente de información son
los datos. Es por esto que si vemos valores muy chicos (grandes) en nuestra
muestra, el intervalo se tiene que extender a la izquierda (derecha) para
compensar dichas observaciones.

*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:
Explica por qué cuando la aproximación normal es apropiada, el intervalo de
percentiles al $95\%$ es muy similar al intervalo normal de 2 errores estándar.

** Ejemplo 

Consideramos los datos de propinas. Queremos estimar la media de cuentas
totales para la comida y la cena. Podemos hacer bootstrap de cada grupo
por separado:

#+begin_src R :exports both :results org
  ## en este ejemplo usamos rsample, pero puedes escribir tu propio código
  library(rsample)
  propinas <- read_csv("data/propinas.csv",
                       progress = FALSE,
                       show_col_types = FALSE) |>
    mutate(id = 1:244)
  propinas
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 244 × 7
   cuenta_total propina fumador dia   momento num_personas    id
          <dbl>   <dbl> <chr>   <chr> <chr>          <dbl> <int>
 1        17.0     1.01 No      Dom   Cena               2     1
 2        10.3     1.66 No      Dom   Cena               3     2
 3        21.0     3.5  No      Dom   Cena               3     3
 4        23.7     3.31 No      Dom   Cena               2     4
 5        24.6     3.61 No      Dom   Cena               4     5
 6        25.3     4.71 No      Dom   Cena               4     6
 7         8.77    2    No      Dom   Cena               2     7
 8        26.9     3.12 No      Dom   Cena               4     8
 9        15.0     1.96 No      Dom   Cena               2     9
10        14.8     3.23 No      Dom   Cena               2    10
# … with 234 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src

#+begin_src R :exports code :results none 
  ## paso 1: define el estimador
  estimador <- function(split, ...){
    muestra <- analysis(split) |> group_by(momento)
    muestra |>
      summarise(estimate = mean(cuenta_total), .groups = 'drop') |>
      mutate(term = momento)
  }
#+end_src

#+begin_src R :exports both :results org 
  ## paso 2: remuestrea y calcula estimador
  boot_samples <- bootstraps(propinas, strata = momento, 1000) |>
    mutate(res_boot = map(splits, estimador))
  ## paso 3: construye intervalos de confianza
  intervalo_propinas_90 <- boot_samples |>
    int_pctl(res_boot, alpha = 0.10) |> 
    mutate(across(where(is.numeric), round, 2))
  intervalo_propinas_90
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 2 × 6
  term   .lower .estimate .upper .alpha .method   
  <chr>   <dbl>     <dbl>  <dbl>  <dbl> <chr>     
1 Cena     19.6      20.8   21.9    0.1 percentile
2 Comida   15.5      17.1   18.5    0.1 percentile
#+end_src

Nota: ~.estimate~ es la media de los valores de la estadística sobre las
remuestras, *no* es el estimador original.

De la tabla anterior inferimos que la media en la cuenta en la cena es más
grande que la de la comida.  Podemos graficar agregando los estimadores /plug-in/:

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/propinas-bootstrap.jpeg :exports results :results output graphics file
  estimadores <- propinas |>
    group_by(momento) |> 
    rename(term = momento) |> 
    summarise(media = mean(cuenta_total))

  ggplot(intervalo_propinas_90, aes(x = term)) +
    geom_linerange(aes(ymin = .lower, ymax = .upper)) +
    geom_point(data = estimadores, aes(y = media), colour = "red", size = 3) +
    xlab("Momento") + ylab("Media de cuenta total (dólares)") +
    labs(subtitle = "Intervalos de 90% para la media") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/propinas-bootstrap.jpeg]]

Nótese que el /bootstrap/ lo hicimos por separado en cada momento del día (por eso
el argumento ~strata~ en la llamada a *bootstraps*):

*** ~Funciones de cómputo~: 

Es común crear nuestras propias funciones cuando usamos /bootstrap/, sin embargo,
en R también hay alternativas que pueden resultar convenientes:

1. El paquete ~rsample~ (forma parte de la colección [[https://www.tidyverse.org/articles/2018/08/tidymodels-0-0-1/][tidymodels]] y tiene una
   función para realizar el remuestreo: ~bootsrtraps()~ que regresa un arreglo
   cuadrangular (~tibble~, ~data.frame~) que incluye una columna con las muestras
   bootstrap y un identificador del número y tipo de muestra.

   #+begin_src R :exports both :results org 
     boot_samples
   #+end_src

   #+RESULTS:
   #+begin_src org
   # Bootstrap sampling using stratification 
   # A tibble: 1,000 × 3
      splits            id            res_boot        
      <list>            <chr>         <list>          
    1 <split [244/91]>  Bootstrap0001 <tibble [2 × 3]>
    2 <split [244/100]> Bootstrap0002 <tibble [2 × 3]>
    3 <split [244/95]>  Bootstrap0003 <tibble [2 × 3]>
    4 <split [244/83]>  Bootstrap0004 <tibble [2 × 3]>
    5 <split [244/91]>  Bootstrap0005 <tibble [2 × 3]>
    6 <split [244/86]>  Bootstrap0006 <tibble [2 × 3]>
    7 <split [244/98]>  Bootstrap0007 <tibble [2 × 3]>
    8 <split [244/83]>  Bootstrap0008 <tibble [2 × 3]>
    9 <split [244/86]>  Bootstrap0009 <tibble [2 × 3]>
   10 <split [244/84]>  Bootstrap0010 <tibble [2 × 3]>
   # … with 990 more rows
   # ℹ Use `print(n = ...)` to see more rows
   #+end_src

   Los objetos ~splits~ tienen muestras de tamaño 244. Sin embargo, utilizan (por
   el muestreo aleatorio con reemplazo) una fracción de los datos.

   #+begin_src R :exports both :results org 
     boot_samples$splits[[1]]
   #+end_src

   #+RESULTS:
   #+begin_src org
   <Analysis/Assess/Total>
   <244/91/244>
   #+end_src

   #+begin_src R :exports both :results org 
     analysis(boot_samples$splits[[1]]) |>
       group_by(id)
   #+end_src

   #+RESULTS:
   #+begin_src org
   # A tibble: 244 × 7
   # Groups:   id [153]
      cuenta_total propina fumador dia   momento num_personas    id
             <dbl>   <dbl> <chr>   <chr> <chr>          <dbl> <int>
    1         21.0    3.5  No      Dom   Cena               3     3
    2         21.0    3.5  No      Dom   Cena               3     3
    3         24.6    3.61 No      Dom   Cena               4     5
    4         25.3    4.71 No      Dom   Cena               4     6
    5         25.3    4.71 No      Dom   Cena               4     6
    6         26.9    3.12 No      Dom   Cena               4     8
    7         15.0    1.96 No      Dom   Cena               2     9
    8         14.8    3.23 No      Dom   Cena               2    10
    9         14.8    3.23 No      Dom   Cena               2    10
   10         14.8    3.23 No      Dom   Cena               2    10
   # … with 234 more rows
   # ℹ Use `print(n = ...)` to see more rows
   #+end_src

   El paquete de ~rsample~ es un paquete muy eficiente para la creación de
   los conjunto de remuestreo y es una de sus principales ventajas. 

   #+begin_src R :exports both :results org 
     library(pryr)
     c(objeto_boot = object_size(boot_samples),
       original    = object_size(propinas),
       remuestra   = object_size(boot_samples)/nrow(boot_samples), 
       incremento  = object_size(boot_samples)/object_size(propinas))
   #+end_src

   #+RESULTS:
   #+begin_src org
   objeto_boot:  2.40 MB
   original   : 16.38 kB
   remuestra  :  2.40 kB
   incremento : 146.25 B
   #+end_src

2. El paquete ~boot~ está asociado al libro *Bootstrap Methods and Their
   Applications* y tiene, entre otras, funciones para calcular replicaciones
   /bootstrap/ y para construir intervalos de confianza usando /bootstrap/:
   1. calculo de replicaciones /bootstrap/ con la función ~boot()~,
   2. intervalos normales, de percentiles y $\mathsf{BC}_a$ con la función ~boot.ci()~,
   3. intevalos ABC con la función ~abc.ci()~.
    
3. El paquete ~bootstrap~ contiene datos usados en citep:Efron1993, y la implementación de
   funciones para calcular replicaciones y construir intervalos de confianza:
   1. calculo de replicaciones /bootstrap/ con la función ~bootstrap()~,
   2. intervalos $\mathsf{BC}_a$ con la función ~bcanon()~, 
   3. intevalos ABC con la función ~abcnon()~.

*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:
Justifica el procedimiento de hacer el /bootstrap/ separado para cada grupo. ¿Qué supuestos
acerca del muestreo se deben satisfacer? ¿Deben ser muestras aleatorias simples 
de cada momento del día, por ejemplo? ¿Qué harías si no fuera así, por ejemplo, si 
se escogieron al azar tickets de todos los disponibles en un periodo?

*  Conclusiones y observaciones 

- El principio fundamental del /bootstrap/ es que podemos estimar
  la distribución poblacional con la distribución empírica. Por tanto para hacer
  inferencia tomamos muestras con reemplazo de la distribución empírica y
  analizamos la variación de la estadística de interés a lo largo de las
  muestras.

- El bootstrap nos da la posibilidad de crear intervalos de confianza cuando no
  contamos con fórmulas para hacerlo de manera analítica y sin supuestos
  distribucionales de la población.

- Hay muchas opciones para construir intervalos bootstrap, los que tienen
  mejores propiedades son los intervalos $\mathsf{BC}_a$, sin embargo los más
  comunes son los intervalos normales con error estándar /bootstrap/ y los
  intervalos de percentiles de la distribución /bootstrap/.

- Antes de hacer intervalos normales (o con percentiles de una $t$) vale la pena
  graficar la distribución /bootstrap/ y evaluar si el supuesto de normalidad es
  razonable.

- En cuanto al número de muestras bootstrap se recomienda al menos $1,000$ al
  hacer pruebas, y $10 , 000$ o $15 , 000$ para los resultados finales, sobre
  todo cuando se hacen intervalos de confianza de percentiles.

- La función de distribución empírica es una mala estimación en las colas de las
  distribuciones, por lo que es difícil construir intervalos de confianza
  (usando bootstrap no paramétrico) para estadísticas que dependen mucho de las
  colas.

bibliographystyle:abbrvnat
bibliography:references.bib



