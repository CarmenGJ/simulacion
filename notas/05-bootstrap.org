#+TITLE: EST-24107: Simulación
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Remuestreo~
#+STARTUP: showall
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/05-bootstrap.pdf
:END:
#+PROPERTY: header-args:R :session bootstrap :exports both :results output org :tangle ../rscript/05-bootstrap.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc noexport

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Otoño, 2022 | /Bootstrap/.\\
*Objetivo*: Que veremos.\\
*Lectura recomendada*: Referencia.
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)

  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 4)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src

* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
  - [[#contexto-histórico][Contexto histórico]]
  - [[#idea-general][Idea general]]
  - [[#ejemplo][Ejemplo]]
    - [[#ejercicio][Ejercicio:]]
  - [[#observaciones][Observaciones:]]
- [[#la-idea-del-bootstrap][La idea del bootstrap]]
  - [[#definición][Definición:]]
  - [[#ejemplo][Ejemplo:]]
- [[#el-principio-de-plug-in][El principio de plug-in]]
  - [[#observación][Observación:]]
    - [[#ejercicio][Ejercicio:]]
  - [[#observación][Observación]]
  - [[#observación][Observación]]
  - [[#ejemplo][Ejemplo]]
:END:



* Introducción 

El remuestreo se refiere a un conjunto de técnicas estadísticas,
computacionalmente intensivas, que ~estiman~ la /distribución de una población/
basadas en ~muestreo aleatorio con reemplazo~.

Se considera que una muestra aleatoria X1 , X2 , . . . , Xn como si fuera una
población finita y se generan muestras aleatorias de la misma muestra para
estimar características poblacionales y hacer inferencia de la población
muestreada.

Las técnicas de remuestreo permiten calcular medidas de ajuste (en términos de
sesgo, varianza, intervalos de confianza, errores de predicción o de algunas
otras medidas) a los estimados basados en muestras.

Estas técnicas son usualmente no paramétricas, y varias son tan antiguas como la
estadística misma. Por ejemplo, las técnicas de permutación son de Fisher (1935)
y Pitmann (1937); la validación cruzadas fue propuesta por Kurtz en 1948, y el
Jackknife fue propuesto por Maurice Quenouille en 1949 aunque fue John Tukey en
1958 quién le dio el nombre a la técnica.

** Contexto histórico

Bradley Efron introdujo el Bootstrap en 1979, y sus estudiantes Rob Tibshirani y
Trevor Hastie han aportado mucho a la ciencia estadística. Ofrecen un curso en
Statistical Learning en la plataforma MOOC de la Universidad de Stanford.

El término ‘bootstrapping’ se refiere al concepto de “pulling oneself up by
one’s bootstraps”, frase que aparentemente se usó por primera vez en The
Singular Travels, Campaigns and Adventures of Varon Munchausen.

** Idea general

El objetivo del remuestreo es estimar alguna característica poblacional, representada por θ (tal
como media, mediana, desviación estándar, coeficientes de regresión, matriz de covarianza,
etc.) basado en los datos.

También interesan las propiedades de la distribución de estimador, sin hacer supuestos
restrictivos sobre la forma de la distribución de los datos originales.

Para una muestra aleatoria X1 , . . . , Xn , la distribución de remuestreo es la distribución
empírica F̂n , que asigna probabilidad 1/n a cada una de las observaciones de la muestra.

\newpage

** Ejemplo

Consideremos una muestra de 6 parejas. La variable de interés es la diferencia
del ingreso de los miembros de cada pareja (en miles de pesos al mes).

|-----+-------------+-------------+-------------------------------|
| $i$ | $P_i^{(1)}$ | $P_i^{(2)}$ | $d_i = P_i^{(1)} - P_i^{(2)}$ |
|-----+-------------+-------------+-------------------------------|
|   1 |          24 |          18 |                             6 |
|   2 |          14 |          17 |                            -3 |
|   3 |          40 |          35 |                             5 |
|   4 |          44 |          41 |                             3 |
|   5 |          35 |          37 |                            -2 |
|   6 |          45 |          45 |                             0 |
|-----+-------------+-------------+-------------------------------|

#+REVEAL: split
Definamos $\theta$ como el promedio de las diferencias de ingreso poblacional. Podemos estimar $\theta$ con
\begin{align}
\hat \theta_n= \frac{6 - 3 + 5 + 3 - 2+ 0}{6} = 1.5\,.
\end{align}
¿Cómo calculamos la variabilidad de nuestro estimador? Es decir, ¿cómo
calculamos la variabilidad de $\hat \theta_n$?

*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:
Escribe la fórmula del error estándar bajo los siguientes supuestos:
1. La diferencia tiene una distribución $d_i \sim \mathsf{N}(\theta, \sigma^2)$.
2. La varianza $\sigma^2$ es conocida.

** ~Observaciones~:
- Suponer que la diferencia de ingresos es $d_i$ como una variable normal puede
  no estar /tan/ errado. Pues con un número suficiente de muestras podríamos
  suponer que el resultado del $\mathsf{TLC}$ se cumple. Entonces, ¿qué hacemos
  si no conocemos la distribución de las observaciones?

- Si no conocemos $\sigma^2$  lo podemos estimar con la muestra. Por ejemplo, podemos
  utilizar intervalos de confianza derivados de una distribución $t$.

- Si nos interesa otro parámetro de la población podemos construir estimadores
  diferentes. Por ejemplo, nos podría interesar la ~mediana~ de una población
  $q_{0.5} = \mathbb{P}^{-1}(1/2)$. Para este caso, podemos estimar dicho parámetro
  por medio de
  \begin{align}
  \hat q_{0.5} = \begin{cases}
    X_{(\frac{n+1}{2})} & \text{ si } n \text{ es impar }\\
    \frac{X_{(n/2)} + X_{(n/2 + 1)}}{2} & \text{ si } n \text{ es par }
  \end{cases} \,.
  \end{align}


#+REVEAL: split
  En [[fig-medianas]] la estimación de la mediana en distintos grupos acompañados de su estimación de incertidumbre. 
#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-medianas-grupos.jpeg :exports results :results output graphics file :tangle no :eval never
    set.seed(8)
    ## Generamos nuestros datos ficticios - poblacion 
    pob_tab <- tibble(id = 1:2000,
                      x = rgamma(2000, 4, 1), 
                      grupo = sample(c("a","b", "c"),
                                     2000, prob = c(4,2,1),
                                     replace = T))
    ## Generamos una muestras - observaciones 
    muestra_tab <- pob_tab |> 
      sample_n(125)
    g_1 <- ggplot(muestra_tab, aes(x = grupo, y = x)) + 
      geom_boxplot(outlier.alpha = 0) +
      geom_jitter(alpha = 0.3) +  sin_lineas + 
      labs(subtitle = "Muestra \n") + ylim(c(0,14))
    ## Hacemos bootstrap 
    fun_boot <- function(datos){
        datos |> group_by(grupo) |>
          sample_n(n(), replace = TRUE)
    }
    reps_boot <- map_df(1:2000, function(i){
      muestra_tab %>% 
        fun_boot %>%
        group_by(grupo) %>%
        summarise(mediana = median(x), .groups = "drop")}, 
      .id = 'rep') 
    resumen_boot <- reps_boot |> group_by(grupo) |> 
        summarise(ymin = quantile(mediana, 0.025), 
                  ymax = quantile(mediana, 0.975), .groups = "drop") |> 
        left_join(muestra_tab |> 
                    group_by(grupo) |> 
                    summarise(mediana = median(x)), .groups = "drop")
    g_2 <- ggplot(resumen_boot, aes(x = grupo, y = mediana, ymin = ymin, 
                                    ymax = ymax)) +
        geom_linerange() + sin_lineas +
        geom_point(colour = "red", size = 2) +  ylim(c(0,14)) +
        labs(subtitle = "Intervalos de 95% \n para la mediana")
    g_1 + g_2
#+end_src
#+name: fig-medianas
#+caption:Estimación de mediana (panel izquierdo) con intervalos de incertidumbre (panel derecho). 
#+RESULTS:
[[file:../images/bootstrap-medianas-grupos.jpeg]]

* La idea del /bootstrap/

Como explicamos, el problema que tenemos ahora es que normalmente sólo tenemos
una muestra, así que no es posible calcular las distribuciones de muestreo como
hicimos arriba y evaluar qué tan preciso es nuestro estimador. Sin embargo,
podemos hacer lo siguiente:

Supongamos que tenemos una muestra $X_1,X_2,\dots, X_n$ independientes de alguna
población desconocida y un estimador $T=t(X_1,\dots, X_n)$

*Mundo poblacional*

1. Si tuviéramos la distribución poblacional, simulamos muestras iid para
aproximar la distribución de muestreo de nuestro estimador, y así entender su
variabilidad.
2. Pero **no** tenemos la distribución poblacional.
3. **Sin embargo, podemos estimar la distribución poblacional con nuestros valores muestrales**.

*Mundo bootstrap*

4. Si usamos la estimación del inciso 3, entonces usando el inciso 1 podríamos
tomar muestras de nuestros datos muestrales, como si fueran de la población, y
usando el mismo tamaño de muestra. El muestreo lo hacemos con reemplazo de 
manera que produzcamos muestras independientes de la misma "población estimada",
que es la muestra.
5. Evaluamos nuestra estadística en cada una de estas remuestras.
6. A la distribución resultante le llamamos **distribución bootstrap** o
**distribución de remuestreo** del estimador.
7. Usamos la distribución bootstrap de la muestra para estimar la variabilidad
en nuestra estimación con **la muestra original**.

Veamos que sucede para un ejemplo concreto, donde  nos interesa estimar
la media de los precios de venta de una población de casas. Tenemos nuestra muestra:

#+begin_src R :exports both :results none
  set.seed(2112)
  poblacion_casas <- read_csv("data/casas.csv")
  muestra <- sample_n(poblacion_casas, 200, replace = TRUE)
#+end_src

#+begin_src R :exports both :results org 
  mean(muestra$precio_miles)  
#+end_src

#+RESULTS:
#+begin_src org
[1] 180
#+end_src

Esta muestra nos da nuestro estimador de la distribución poblacional. Por ejemplo, podemos fijarnos en un gráfico de cuantiles:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-qqplot.jpeg :exports results :results output graphics file
  bind_rows(muestra %>% mutate(tipo = "muestra"),
      poblacion_casas %>% mutate(tipo = "población")) |>  
  ggplot(aes(sample = precio_miles, colour = tipo, group = tipo)) + 
    geom_qq(distribution = stats::qunif, alpha = 0.4, size = 1) +
    facet_wrap(~ tipo) + sin_lineas + sin_leyenda
#+end_src

#+RESULTS:
[[file:../images/casas-qqplot.jpeg]]

O en histogramas:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-histogramas.jpeg :exports results :results output graphics file
  bind_rows(muestra %>% mutate(tipo = "muestra"),
      poblacion_casas %>% mutate(tipo = "población")) %>% 
  ggplot(aes(x = precio_miles, group = tipo)) + 
      geom_histogram(aes(y=..density..), binwidth = 50) + 
    facet_wrap(~ tipo) + sin_lineas + sin_leyenda
#+end_src

#+RESULTS:
[[file:../images/casas-histogramas.jpeg]]

Y vemos que la aproximación es razonable en las partes centrales de la 
distribución. 

Ahora supongamos que nos interesa cuantificar la precisión de nuestra
estimación de la media poblacional de precios de casas, y usaremos la media
muestral para hacer esto. Para nuestra muestra, nuestra estimación puntual es:

#+begin_src R :exports both :results org 
  media <- mean(muestra$precio_miles)
  media
#+end_src

#+RESULTS:
#+begin_src org
[1] 180
#+end_src


Y recordamos que para aproximar la distribución de muestreo podíamos muestrear
repetidamente la población y calcular el valor del estimador en cada una de
estas muestras. Aquí no tenemos la población, *pero tenemos una estimación de la
población*: la muestra obtenida.

Así que para evaluar la variabilidad de nuestro estimador, entramos en el mundo
boostrap, y consideramos que la población es nuestra muestra.

Podemos entonces extraer un número grande de muestras con reemplazo de tamaño
200 *de la muestra*: el muestreo debe ser análogo al que se tomó para nuestra
muestra original. Evaluamos nuestra estadística (en este caso la media) en cada
una de estas remuestras:

#+begin_src R :exports both :results org 
  media_muestras <- map_dbl(1:1000, ~ muestra %>%  
          sample_n(200, replace = T) %>%
          summarise(media_precio = mean(precio_miles), .groups = "drop") %>%
          pull(media_precio))
  media_muestras[1:10]
#+end_src

#+RESULTS:
#+begin_src org
 [1] 177.3 169.3 180.1 183.9 184.7 180.4 188.9 178.8 180.9 177.9
#+end_src

Y nuestra estimación de la distribución de muestreo para la media es entonces:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-bootstrap.jpeg :exports results :results output graphics file
  bootstrap <- tibble(media = media_muestras)
  g_cuantiles <- ggplot(bootstrap, aes(sample = media)) +
    geom_qq(distribution = stats::qunif) +
    sin_lineas
  g_histograma <- ggplot(bootstrap, aes(x = media)) +
    geom_histogram(binwidth = 2) + sin_lineas
  g_cuantiles + g_histograma
#+end_src

#+RESULTS:
[[file:../images/casas-bootstrap.jpeg]]

A esta le llamamos la distribución de remuestreo de la media, que definimos más
abajo. Ahora podemos calcular un intervalo de confianza del 90\% simplemente
calculando los cuantiles de esta distribución (no son los cuantiles de la
muestra original!):

#+begin_src R :exports both :results org 
  limites_ic <- quantile(media_muestras, c(0.05,  0.95)) %>% round
  limites_ic
#+end_src

#+RESULTS:
#+begin_src org
 5% 95% 
171 190
#+end_src

Otra cosa que podríamos hacer para describir la dispersión de nuestro estimador
es calcular el error estándar de remuestreo, que estima el error estándar de la
distribución de muestreo:

#+begin_src R :exports both :results org
  ee_boot <- sd(media_muestras)
  round(ee_boot, 2)
#+end_src

#+RESULTS:
#+begin_src org
[1] 5.55
#+end_src

*** ~Definición~:
Sea $X_1,X_2,\ldots,X_n$ una muestra independiente y idénticamente
distribuida, y $T=t(X_1, X_2, \ldots, X_n)$ una estadística. Supongamos que sus valores
que obervamos son $x_1, x_2,\ldots, x_n$.

La **distribución de remuestreo** de $T$ es la
distribución de $T^*=t(X_1^*, X_2^*, \dots X_n^*)$, donde cada $X_i^*$ se obtiene
tomando al azar uno de los valores de $x_1,x_2,\ldots, x_n$.

Otra manera de decir esto es que la remuestra $X_1^*, X_2^*, \ldots, X_n^*$ es una muestra
con reemplazo de los valores observados $x_1, x_2, \ldots, x_n$


*** ~Ejemplo~:
Si observamos la muestra

#+begin_src R :exports both :results org 
  muestra <- sample(1:20, 5)
  muestra
#+end_src

#+RESULTS:
#+begin_src org
[1]  2  9 10  1 18
#+end_src

Una remuestra se obtiene:

#+begin_src R :exports both :results org 
  sample(muestra, size = 5, replace = TRUE)
#+end_src

#+RESULTS:
#+begin_src org
[1]  9 10  2 10 10
#+end_src

Nótese que algunos valores de la muestra original pueden aparecer varias veces, y otros no aparecen del todo.

** Nota
*La idea del bootstrap*. La muestra original es una aproximación de la población
de donde fue extraída. Así que remuestrear la muestra aproxima lo que pasaría si
tomáramos muestras de la población. La *distribución de remuestreo* de una
estadística, que se construye tomando muchas remuestras, aproxima la
distribución de muestreo de la estadística.


Y el proceso que hacemos es:

*** ~Remuestreo para una población~:
Dada una muestra de tamaño $n$ de una población, 

1. Obtenemos una remuestra de tamaño $n$ con reemplazo de la muestra original
2. Repetimos este remuestreo muchas veces (por ejemplo, 10,000).
3. Construímos la distribución bootstrap, y examinamos sus características 
(dónde está centrada, dispersión y forma).

* El principio de /plug-in/

La idea básica detrás del /bootstrap/ es el principio de /plug-in/ para estimar
parámetros poblacionales: si queremos estimar una cantidad poblacional,
calculamos esa cantidad poblacional con la muestra obtenida. Es un principio
común en estadística.

Por ejemplo, si queremos estimar la media o desviación estándar poblacional,
usamos la media muestral o la desviación estándar muestral. Si queremos estimar
un cuantil de la población usamos el cuantil correspondiente de la muestra, y
así sucesivamente.

En todos estos casos, lo que estamos haciendo es:

- Tenemos una fórmula para la cantidad poblacional de interés en términos de la
distribución poblacional.  
- Tenemos una muestra, que usamos para estimar la cantidad poblacional. La
distribución que da una muestra se llama distribución *empírica*.
- Contruimos nuestro estimador "enchufando" la distribución empírica de la
muestra en la fórmula del estimador.

En el bootstrap aplicamos este principio simple a la *distribución de 
muestreo*:

- *Si tenemos la población*, podemos *calcular* la distribución de muestreo de
nuestro estimador tomando muchas muestras de la *población*.
- Estimamos la *poblacion* con la *muestra* y enchufamos en la frase anterior:
- Podemos *estimar* la distribucion de muestreo de nuestro estimador
tomando muchas muestras de la *muestra* (bootstrap).

Nótese que el proceso de muestreo en el último paso **debe ser el mismo** que
se usó para tomar la muestra original. Estas dos imágenes simuladas con base en 
un ejemplo de citep:Chihara2018 muestran lo que acabamos de describir:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/mundo-poblacional.jpeg :exports results :results output graphics file
  library(LaplacesDemon)
  library(patchwork)
  ## En este ejemplo la población es una mezcla de normales
  pob_plot <- ggplot(data_frame(x = -15:20), aes(x)) +
    stat_function(fun = dnormm, args = list(p = c(0.3, 0.7), mu = c(-2, 8),
                                            sigma = c(3.5, 3)), alpha = 0.8) +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    scale_colour_manual(values = c('mu' = 'red'), name = '', 
                        labels = expression(mu)) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", subtitle = expression("Población "~F), color = "") +
    theme_classic()

  samples <- data_frame(sample = 1:3) %>% 
    mutate(
      sims = rerun(3, rnormm(30, p = c(0.3, 0.7), mu = c(-2, 8), 
                             sigma = c(3.5, 3))), 
      x_bar = map_dbl(sims, mean))
  muestras_plot <- samples %>% 
    unnest(cols = c(sims)) %>% 
    ggplot(aes(x = sims)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_segment(aes(x = x_bar, xend = x_bar, y = 0, yend = 0.8), 
                 color = "blue") +
    xlim(-15, 20) +
    facet_wrap(~ sample) +
    scale_y_continuous(breaks = NULL) +
    geom_text(aes(x = x_bar, y = 0.95, label = "bar(x)"), parse = TRUE, 
              color = "blue", alpha = 0.2, hjust = 1) +
    labs(x = "", subtitle = "Muestras") +
    theme_classic() +
    theme(strip.background = element_blank(), strip.text.x = element_blank())

  samples_dist <- tibble(sample = 1:10000) %>% 
    mutate(sims = rerun(10000, rnormm(100, p = c(0.3, 0.7), mu = c(-2, 8), 
                                      sigma = c(3.5, 3))), 
           mu_hat = map_dbl(sims, mean))
  dist_muestral_plot <- ggplot(samples_dist, aes(x = mu_hat)) +
    geom_density(adjust = 2) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", y = "",
         subtitle = expression("Distribución muestral de "~hat(mu)==bar(X))) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    theme_classic()

  (pob_plot | plot_spacer()) / (muestras_plot | dist_muestral_plot) 
#+end_src

#+RESULTS:
[[file:../images/chihara-ejemplo.jpeg]]


#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/mundo-bootstrap.jpeg :exports results :results output graphics file
  dist_empirica <- tibble(id = 1:30, obs = samples$sims[[1]])

  dist_empirica_plot <- ggplot(dist_empirica, aes(x = obs)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    geom_vline(aes(xintercept = samples$x_bar[1], color = "x_bar"), 
               alpha = 0.8, linetype = "dashed") +
    xlim(-15, 20) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    labs(x = "", subtitle = expression("Distribución empírica"~hat(F))) +
    scale_colour_manual(values = c('mu' = 'red', 'x_bar' = 'blue'), name = '', 
                        labels = c(expression(mu), expression(bar(x)))) +
    scale_y_continuous(breaks = NULL) +
    theme_classic()

  samples_boot <- tibble(sample_boot = 1:3) %>% 
    mutate(
      sims_boot = rerun(3, sample(dist_empirica$obs, replace = TRUE)), 
      x_bar_boot = map_dbl(sims_boot, mean)
    )

  muestras_boot_plot <- samples_boot %>% 
    unnest(cols = c(sims_boot)) %>% 
    ggplot(aes(x = sims_boot)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(xintercept = samples$x_bar[1]), color = "blue",
               linetype = "dashed", alpha = 0.8) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_segment(aes(x = x_bar_boot, xend = x_bar_boot, y = 0, yend = 0.8), 
                 color = "black") +
    xlim(-15, 20) +
    facet_wrap(~ sample_boot) +
    geom_text(aes(x = x_bar_boot, y = 0.95, label = "bar(x)^'*'"), 
              parse = TRUE, color = "black", alpha = 0.3, hjust = 1) +
    labs(x = "", subtitle = "Muestras bootstrap") +
    scale_y_continuous(breaks = NULL) +
    theme_classic() +
    theme(strip.background = element_blank(), strip.text.x = element_blank())

  boot_dist <- data_frame(sample = 1:10000) %>% 
    mutate(
      sims_boot = rerun(10000, sample(dist_empirica$obs, replace = TRUE)), 
      mu_hat_star = map_dbl(sims_boot, mean))
  boot_muestral_plot <- ggplot(boot_dist, aes(x = mu_hat_star)) +
    geom_histogram(alpha = 0.5, fill = "darkgray", bins = 30) +
    labs(x = "", 
         subtitle = expression("Distribución bootstrap de "~hat(mu)^'*'==bar(X))) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_vline(aes(xintercept = samples$x_bar[1]), color = "blue", 
               linetype = "dashed", alpha = 0.8) +
    scale_y_continuous(breaks = NULL) +
    theme_classic()

  (dist_empirica_plot | plot_spacer()) / (muestras_boot_plot | boot_muestral_plot) 
#+end_src

#+RESULTS:
[[file:../images/mundo-bootstrap.jpeg]]

** Observación: 
Veremos ejemplos más complejos, pero nótese que si la muestra original son
observaciones independientes obtenidas de la distribución poblacional, entonces
logramos esto en las remuestras tomando observaciones con reemplazo de la
muestra. Igualmente, las remuestras deben ser del mismo tamaño que la muestra
original.

*** ~Ejercicio~:
- ¿Porqué no funcionaría tomar muestras sin reemplazo? Piensa si hay independencia
entre las observaciones de la remuestra, y cómo serían las remuestras sin reemplazo.
- ¿Por qué no se puede hacer bootstrap si no conocemos cómo se obtuvo la muestra original?


** Observación
Estos argumentos se pueden escribir con fórmulas usando por ejemplo la función
de distribución acumulada $F$ de la población y su estimador, que es la función
empírica $\hat{F}$, como en citep:Efron1993.  Si $\theta = t(F)$ es una cantidad
poblacional que queremos estimar, su estimador /plug-in/ es $\hat{\theta} =
t(\hat{F})$.

** Observación
La distribución empírica $\hat{F}$ es un estimador "razonable" de la
distribución poblacional $F,$ pues por el teorema de Glivenko-Cantelli
(citep:Wasserman2004, o
[aquí](https://en.wikipedia.org/wiki/Glivenko-Cantelli_theorem)), $\hat{F}$
converge a $F$ cuando el tamaño de muestra $n\to\infty$, lo cual es
intuitivamente claro.

** Ejemplo 
En el siguiente ejemplo (tomadores de té), podemos estimar la proporción de
tomadores de té que prefiere el té negro usando nuestra muestra:

#+begin_src R :exports both :results none
  te <- read_csv("data/tea.csv") |>
    rowid_to_column() |>
    select(rowid, Tea, sugar)
#+end_src

#+begin_src R :exports both :results org 
  te |>
    mutate(negro = ifelse(Tea == "black", 1, 0)) |>
    summarise(prop_negro = mean(negro), n = length(negro), .groups = "drop")
#+end_src


#+RESULTS:
#+begin_src org
# A tibble: 1 × 2
  prop_negro     n
       <dbl> <int>
1      0.247   300
#+end_src

¿Cómo evaluamos la precisión de este estimador? Supondremos que el estudio se
hizo tomando una muestra aleatoria simple de tamaño 300 de la población de tomadores de té que
nos interesa. Podemos entonces usar el boostrap:

#+begin_src R :exports code :results none 
  ## paso 1: define el estimador
  calc_estimador <- function(datos){
    prop_negro <- datos |>
      mutate(negro = ifelse(Tea == "black", 1, 0)) |>
      summarise(prop_negro = mean(negro), n = length(negro), .groups = "drop") |>
      pull(prop_negro)
    prop_negro
  }  
#+end_src

#+begin_src R :exports code :results none 
  ## paso 2: define el proceso de remuestreo
  muestra_boot <- function(datos){
    ## tomar muestra con reemplazo del mismo tamaño
    sample_n(datos, size = nrow(datos), replace = TRUE)
  }  
#+end_src

#+begin_src R :exports code :results none 
  # paso 3: remuestrea y calcula el estimador
  prop_negro_tbl <- map_dbl(1:2000,  ~ calc_estimador(muestra_boot(datos = te))) %>%
    tibble(prop_negro = .)  
#+end_src

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-tea-mean.jpeg :exports results :results output graphics file
  ## paso 4: examina la distribución bootstrap
  prop_negro_tbl %>% 
    ggplot(aes(x = prop_negro)) +
    geom_histogram(bins = 15) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/bootstrap-tea-mean.jpeg]]

Y podemos evaluar varios aspectos, por ejemplo dónde está centrada y 
qué tan dispersa es la distribución bootstrap:

#+begin_src R :exports both :results org 
  prop_negro_tbl |>
    summarise(media = mean(prop_negro),
              sesgo = mean(prop_negro) - 0.2499,
              ee = sd(prop_negro),
              cuantil_75 = quantile(prop_negro, 0.75), 
              cuantil_25 = quantile(prop_negro, 0.25),
              .groups = "drop") |>
    mutate(across(where(is.numeric), round, 3)) |>
    pivot_longer(cols = everything())
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 5 × 2
  name        value
  <chr>       <dbl>
1 media       0.247
2 sesgo      -0.003
3 ee          0.025
4 cuantil_75  0.263
5 cuantil_25  0.23
#+end_src

bibliographystyle:abbrvnat
bibliography:references.bib


* Temas por ver                                                    :noexport:

- Jacknife (sesgo, reducción de sesgo)
- Bootstrap (sesgo, reducción de sesgo)
- Pruebas de permutación (pruebas estadisticas exactas)
- Validación cruzada
