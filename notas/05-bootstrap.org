#+TITLE: EST-24107: Simulación
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Remuestreo~
#+STARTUP: showall
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/05-bootstrap.pdf
:END:
#+PROPERTY: header-args:R :session bootstrap :exports both :results output org :tangle ../rscript/05-bootstrap.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc noexport draft

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Otoño, 2022 | /Bootstrap/.\\
*Objetivo*: Que veremos.\\
*Lectura recomendada*: Referencia.
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)

  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 5)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src

* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
  - [[#contexto-histórico][Contexto histórico]]
  - [[#idea-general][Idea general]]
  - [[#ejemplo][Ejemplo]]
    - [[#ejercicio][Ejercicio:]]
  - [[#observaciones][Observaciones:]]
- [[#la-idea-del-bootstrap][La idea del bootstrap]]
  - [[#definición][Definición:]]
  - [[#ejemplo][Ejemplo:]]
- [[#el-principio-de-plug-in][El principio de plug-in]]
  - [[#observación][Observación:]]
    - [[#ejercicio][Ejercicio:]]
  - [[#observación][Observación]]
  - [[#observación][Observación]]
  - [[#ejemplo][Ejemplo]]
- [[#propiedades-distribución-bootstrap][Propiedades distribución bootstrap]]
  - [[#ejemplo][Ejemplo]]
  - [[#variación-en-distribución-bootstrap][Variación en distribución bootstrap]]
- [[#error-estándar-bootstrap-e-intervalos-normales][Error estándar bootstrap e intervalos normales]]
  - [[#definición][Definición:]]
- [[#inventarios-de-casas-vendidas][Inventarios de casas vendidas]]
  - [[#nota][Nota:]]
- [[#calibración-de-intervalos-de-confianza][Calibración de intervalos de confianza]]
  - [[#observación][Observación:]]
- [[#interpretación-intervalos-de-confianza][Interpretación intervalos de confianza]]
- [[#intervalos-bootstrap-de-percentiles][Intervalos bootstrap de percentiles]]
  - [[#definición][Definición:]]
  - [[#ejercicio][Ejercicio:]]
- [[#boostrap-y-otras-estadísticas][Boostrap y otras estadísticas]]
  - [[#estimadores-de-razón][Estimadores de razón]]
  - [[#suavizadores][Suavizadores]]
- [[#conclusiones-y-observaciones][Conclusiones y observaciones]]
:END:



* Introducción 

El remuestreo se refiere a un conjunto de técnicas estadísticas,
computacionalmente intensivas, que ~estiman~ la /distribución de una población/
basadas en ~muestreo aleatorio con reemplazo~.

Se considera que una muestra aleatoria $X_{1}, \ldots, X_{n}$ como si fuera una
población finita y se generan muestras aleatorias de la misma muestra para
estimar características poblacionales y hacer inferencia de la población
muestreada.

Las técnicas de remuestreo permiten calcular medidas de ajuste (en términos de
sesgo, varianza, intervalos de confianza, errores de predicción o de algunas
otras medidas) a los estimados basados en muestras.

Estas técnicas son usualmente no paramétricas, y varias son tan antiguas como la
estadística misma. Por ejemplo, las técnicas de permutación son de Fisher (1935)
y Pitmann (1937); la validación cruzadas fue propuesta por Kurtz en 1948, y el
Jackknife fue propuesto por Maurice Quenouille en 1949 aunque fue John Tukey en
1958 quién le dio el nombre a la técnica.

** Contexto histórico

Bradley Efron introdujo el Bootstrap en 1979, y sus estudiantes Rob Tibshirani y
Trevor Hastie han aportado mucho a la ciencia estadística. Ofrecen un curso en
Statistical Learning en la plataforma MOOC de la Universidad de Stanford.

El término ‘bootstrapping’ se refiere al concepto de “pulling oneself up by
one’s bootstraps”, frase que aparentemente se usó por primera vez en The
Singular Travels, Campaigns and Adventures of Varon Munchausen.

** Idea general

El objetivo del remuestreo es estimar alguna característica poblacional, representada por θ (tal
como media, mediana, desviación estándar, coeficientes de regresión, matriz de covarianza,
etc.) basado en los datos.

También interesan las propiedades de la distribución de estimador, sin hacer supuestos
restrictivos sobre la forma de la distribución de los datos originales.

Para una muestra aleatoria $X_1, \ldots , X_n$ , la distribución de remuestreo es la distribución
empírica $\hat{\mathbb{P}}_n$ , que asigna probabilidad $1/n$ a cada una de las observaciones de la muestra.

\newpage

** Ejemplo

Consideremos una muestra de 6 parejas. La variable de interés es la diferencia
del ingreso de los miembros de cada pareja (en miles de pesos al mes).

|-----+-------------+-------------+-------------------------------|
| $i$ | $P_i^{(1)}$ | $P_i^{(2)}$ | $d_i = P_i^{(1)} - P_i^{(2)}$ |
|-----+-------------+-------------+-------------------------------|
|   1 |          24 |          18 |                             6 |
|   2 |          14 |          17 |                            -3 |
|   3 |          40 |          35 |                             5 |
|   4 |          44 |          41 |                             3 |
|   5 |          35 |          37 |                            -2 |
|   6 |          45 |          45 |                             0 |
|-----+-------------+-------------+-------------------------------|

#+REVEAL: split
Definamos $\theta$ como el promedio de las diferencias de ingreso poblacional. Podemos estimar $\theta$ con
\begin{align}
\hat \theta_n= \frac{6 - 3 + 5 + 3 - 2+ 0}{6} = 1.5\,.
\end{align}
¿Cómo calculamos la variabilidad de nuestro estimador? Es decir, ¿cómo
calculamos la variabilidad de $\hat \theta_n$?

*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:
Escribe la fórmula del error estándar bajo los siguientes supuestos:
1. La diferencia tiene una distribución $d_i \sim \mathsf{N}(\theta, \sigma^2)$.
2. La varianza $\sigma^2$ es conocida.

** ~Observaciones~:
- Suponer que la diferencia de ingresos es $d_i$ como una variable normal puede
  no estar /tan/ errado. Pues con un número suficiente de muestras podríamos
  suponer que el resultado del $\mathsf{TLC}$ se cumple. Entonces, ¿qué hacemos
  si no conocemos la distribución de las observaciones?

- Si no conocemos $\sigma^2$  lo podemos estimar con la muestra. Por ejemplo, podemos
  utilizar intervalos de confianza derivados de una distribución $t$.

- Si nos interesa otro parámetro de la población podemos construir estimadores
  diferentes. Por ejemplo, nos podría interesar la ~mediana~ de una población
  $q_{0.5} = \mathbb{P}^{-1}(1/2)$. Para este caso, podemos estimar dicho parámetro
  por medio de
  \begin{align}
  \hat q_{0.5} = \begin{cases}
    X_{(\frac{n+1}{2})} & \text{ si } n \text{ es impar }\\
    \frac{X_{(n/2)} + X_{(n/2 + 1)}}{2} & \text{ si } n \text{ es par }
  \end{cases} \,.
  \end{align}


#+REVEAL: split
  En [[fig-medianas]] la estimación de la mediana en distintos grupos acompañados de su estimación de incertidumbre. 
#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-medianas-grupos.jpeg :exports results :results output graphics file :tangle no :eval never
    set.seed(8)
    ## Generamos nuestros datos ficticios - poblacion 
    pob_tab <- tibble(id = 1:2000,
                      x = rgamma(2000, 4, 1), 
                      grupo = sample(c("a","b", "c"),
                                     2000, prob = c(4,2,1),
                                     replace = T))
    ## Generamos una muestras - observaciones 
    muestra_tab <- pob_tab |> 
      sample_n(125)
    g_1 <- ggplot(muestra_tab, aes(x = grupo, y = x)) + 
      geom_boxplot(outlier.alpha = 0) +
      geom_jitter(alpha = 0.3) +  sin_lineas + 
      labs(subtitle = "Muestra \n") + ylim(c(0,14))
    ## Hacemos bootstrap 
    fun_boot <- function(datos){
        datos |> group_by(grupo) |>
          sample_n(n(), replace = TRUE)
    }
    reps_boot <- map_df(1:2000, function(i){
      muestra_tab %>% 
        fun_boot %>%
        group_by(grupo) %>%
        summarise(mediana = median(x), .groups = "drop")}, 
      .id = 'rep') 
    resumen_boot <- reps_boot |> group_by(grupo) |> 
        summarise(ymin = quantile(mediana, 0.025), 
                  ymax = quantile(mediana, 0.975), .groups = "drop") |> 
        left_join(muestra_tab |> 
                    group_by(grupo) |> 
                    summarise(mediana = median(x)), .groups = "drop")
    g_2 <- ggplot(resumen_boot, aes(x = grupo, y = mediana, ymin = ymin, 
                                    ymax = ymax)) +
        geom_linerange() + sin_lineas +
        geom_point(colour = "red", size = 2) +  ylim(c(0,14)) +
        labs(subtitle = "Intervalos de 95% \n para la mediana")
    g_1 + g_2
#+end_src
#+name: fig-medianas
#+caption:Estimación de mediana (panel izquierdo) con intervalos de incertidumbre (panel derecho). 
#+RESULTS:
[[file:../images/bootstrap-medianas-grupos.jpeg]]

* La idea del /bootstrap/

Como explicamos, el problema que tenemos ahora es que normalmente sólo tenemos
una muestra, así que no es posible calcular las distribuciones de muestreo como
hicimos arriba y evaluar qué tan preciso es nuestro estimador. Sin embargo,
podemos hacer lo siguiente:

Supongamos que tenemos una muestra $X_1,X_2,\dots, X_n$ independientes de alguna
población desconocida y un estimador $T=t(X_1,\dots, X_n)$

*Mundo poblacional*

1. Si tuviéramos la distribución poblacional, simulamos muestras iid para
aproximar la distribución de muestreo de nuestro estimador, y así entender su
variabilidad.
2. Pero **no** tenemos la distribución poblacional.
3. **Sin embargo, podemos estimar la distribución poblacional con nuestros valores muestrales**.

*Mundo bootstrap*

4. Si usamos la estimación del inciso 3, entonces usando el inciso 1 podríamos
tomar muestras de nuestros datos muestrales, como si fueran de la población, y
usando el mismo tamaño de muestra. El muestreo lo hacemos con reemplazo de 
manera que produzcamos muestras independientes de la misma "población estimada",
que es la muestra.
5. Evaluamos nuestra estadística en cada una de estas remuestras.
6. A la distribución resultante le llamamos **distribución bootstrap** o
**distribución de remuestreo** del estimador.
7. Usamos la distribución bootstrap de la muestra para estimar la variabilidad
en nuestra estimación con **la muestra original**.

Veamos que sucede para un ejemplo concreto, donde  nos interesa estimar
la media de los precios de venta de una población de casas. Tenemos nuestra muestra:

#+begin_src R :exports both :results none
  set.seed(2112)
  poblacion_casas <- read_csv("data/casas.csv")
  muestra <- sample_n(poblacion_casas, 200, replace = TRUE)
#+end_src

#+begin_src R :exports both :results org 
  mean(muestra$precio_miles)  
#+end_src

#+RESULTS:
#+begin_src org
[1] 180
#+end_src

Esta muestra nos da nuestro estimador de la distribución poblacional. Por ejemplo, podemos fijarnos en un gráfico de cuantiles:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-qqplot.jpeg :exports results :results output graphics file
  bind_rows(muestra %>% mutate(tipo = "muestra"),
      poblacion_casas %>% mutate(tipo = "población")) |>  
  ggplot(aes(sample = precio_miles, colour = tipo, group = tipo)) + 
    geom_qq(distribution = stats::qunif, alpha = 0.4, size = 1) +
    facet_wrap(~ tipo) + sin_lineas + sin_leyenda
#+end_src

#+RESULTS:
[[file:../images/casas-qqplot.jpeg]]

O en histogramas:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-histogramas.jpeg :exports results :results output graphics file
  bind_rows(muestra %>% mutate(tipo = "muestra"),
      poblacion_casas %>% mutate(tipo = "población")) %>% 
  ggplot(aes(x = precio_miles, group = tipo)) + 
      geom_histogram(aes(y=..density..), binwidth = 50) + 
    facet_wrap(~ tipo) + sin_lineas + sin_leyenda
#+end_src

#+RESULTS:
[[file:../images/casas-histogramas.jpeg]]

Y vemos que la aproximación es razonable en las partes centrales de la 
distribución. 

Ahora supongamos que nos interesa cuantificar la precisión de nuestra
estimación de la media poblacional de precios de casas, y usaremos la media
muestral para hacer esto. Para nuestra muestra, nuestra estimación puntual es:

#+begin_src R :exports both :results org 
  media <- mean(muestra$precio_miles)
  media
#+end_src

#+RESULTS:
#+begin_src org
[1] 180
#+end_src


Y recordamos que para aproximar la distribución de muestreo podíamos muestrear
repetidamente la población y calcular el valor del estimador en cada una de
estas muestras. Aquí no tenemos la población, *pero tenemos una estimación de la
población*: la muestra obtenida.

Así que para evaluar la variabilidad de nuestro estimador, entramos en el mundo
boostrap, y consideramos que la población es nuestra muestra.

Podemos entonces extraer un número grande de muestras con reemplazo de tamaño
200 *de la muestra*: el muestreo debe ser análogo al que se tomó para nuestra
muestra original. Evaluamos nuestra estadística (en este caso la media) en cada
una de estas remuestras:

#+begin_src R :exports both :results org 
  media_muestras <- map_dbl(1:1000, ~ muestra %>%  
          sample_n(200, replace = T) %>%
          summarise(media_precio = mean(precio_miles), .groups = "drop") %>%
          pull(media_precio))
  media_muestras[1:10]
#+end_src

#+RESULTS:
#+begin_src org
 [1] 177.3 169.3 180.1 183.9 184.7 180.4 188.9 178.8 180.9 177.9
#+end_src

Y nuestra estimación de la distribución de muestreo para la media es entonces:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-bootstrap.jpeg :exports results :results output graphics file
  bootstrap <- tibble(media = media_muestras)
  g_cuantiles <- ggplot(bootstrap, aes(sample = media)) +
    geom_qq(distribution = stats::qunif) +
    sin_lineas
  g_histograma <- ggplot(bootstrap, aes(x = media)) +
    geom_histogram(binwidth = 2) + sin_lineas
  g_cuantiles + g_histograma
#+end_src

#+RESULTS:
[[file:../images/casas-bootstrap.jpeg]]

A esta le llamamos la distribución de remuestreo de la media, que definimos más
abajo. Ahora podemos calcular un intervalo de confianza del 90\% simplemente
calculando los cuantiles de esta distribución (no son los cuantiles de la
muestra original!):

#+begin_src R :exports both :results org 
  limites_ic <- quantile(media_muestras, c(0.05,  0.95)) %>% round
  limites_ic
#+end_src

#+RESULTS:
#+begin_src org
 5% 95% 
171 190
#+end_src

Otra cosa que podríamos hacer para describir la dispersión de nuestro estimador
es calcular el error estándar de remuestreo, que estima el error estándar de la
distribución de muestreo:

#+begin_src R :exports both :results org
  ee_boot <- sd(media_muestras)
  round(ee_boot, 2)
#+end_src

#+RESULTS:
#+begin_src org
[1] 5.55
#+end_src

*** ~Definición~:
Sea $X_1,X_2,\ldots,X_n$ una muestra independiente y idénticamente
distribuida, y $T=t(X_1, X_2, \ldots, X_n)$ una estadística. Supongamos que sus valores
que obervamos son $x_1, x_2,\ldots, x_n$.

La **distribución de remuestreo** de $T$ es la
distribución de $T^*=t(X_1^*, X_2^*, \dots X_n^*)$, donde cada $X_i^*$ se obtiene
tomando al azar uno de los valores de $x_1,x_2,\ldots, x_n$.

Otra manera de decir esto es que la remuestra $X_1^*, X_2^*, \ldots, X_n^*$ es una muestra
con reemplazo de los valores observados $x_1, x_2, \ldots, x_n$


*** ~Ejemplo~:
Si observamos la muestra

#+begin_src R :exports both :results org 
  muestra <- sample(1:20, 5)
  muestra
#+end_src

#+RESULTS:
#+begin_src org
[1]  2  9 10  1 18
#+end_src

Una remuestra se obtiene:

#+begin_src R :exports both :results org 
  sample(muestra, size = 5, replace = TRUE)
#+end_src

#+RESULTS:
#+begin_src org
[1]  9 10  2 10 10
#+end_src

Nótese que algunos valores de la muestra original pueden aparecer varias veces, y otros no aparecen del todo.

** Nota
*La idea del bootstrap*. La muestra original es una aproximación de la población
de donde fue extraída. Así que remuestrear la muestra aproxima lo que pasaría si
tomáramos muestras de la población. La *distribución de remuestreo* de una
estadística, que se construye tomando muchas remuestras, aproxima la
distribución de muestreo de la estadística.


Y el proceso que hacemos es:

*** ~Remuestreo para una población~:
Dada una muestra de tamaño $n$ de una población, 

1. Obtenemos una remuestra de tamaño $n$ con reemplazo de la muestra original
2. Repetimos este remuestreo muchas veces (por ejemplo, 10,000).
3. Construímos la distribución bootstrap, y examinamos sus características 
(dónde está centrada, dispersión y forma).

* El principio de /plug-in/

La idea básica detrás del /bootstrap/ es el principio de /plug-in/ para estimar
parámetros poblacionales: si queremos estimar una cantidad poblacional,
calculamos esa cantidad poblacional con la muestra obtenida. Es un principio
común en estadística.

Por ejemplo, si queremos estimar la media o desviación estándar poblacional,
usamos la media muestral o la desviación estándar muestral. Si queremos estimar
un cuantil de la población usamos el cuantil correspondiente de la muestra, y
así sucesivamente.

En todos estos casos, lo que estamos haciendo es:

- Tenemos una fórmula para la cantidad poblacional de interés en términos de la
distribución poblacional.  
- Tenemos una muestra, que usamos para estimar la cantidad poblacional. La
distribución que da una muestra se llama distribución *empírica*.
- Contruimos nuestro estimador "enchufando" la distribución empírica de la
muestra en la fórmula del estimador.

En el bootstrap aplicamos este principio simple a la *distribución de 
muestreo*:

- *Si tenemos la población*, podemos *calcular* la distribución de muestreo de
nuestro estimador tomando muchas muestras de la *población*.
- Estimamos la *poblacion* con la *muestra* y enchufamos en la frase anterior:
- Podemos *estimar* la distribucion de muestreo de nuestro estimador
tomando muchas muestras de la *muestra* (bootstrap).

Nótese que el proceso de muestreo en el último paso **debe ser el mismo** que
se usó para tomar la muestra original. Estas dos imágenes simuladas con base en 
un ejemplo de citep:Chihara2018 muestran lo que acabamos de describir:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/mundo-poblacional.jpeg :exports results :results output graphics file
  library(LaplacesDemon)
  library(patchwork)
  ## En este ejemplo la población es una mezcla de normales
  pob_plot <- ggplot(data_frame(x = -15:20), aes(x)) +
    stat_function(fun = dnormm, args = list(p = c(0.3, 0.7), mu = c(-2, 8),
                                            sigma = c(3.5, 3)), alpha = 0.8) +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    scale_colour_manual(values = c('mu' = 'red'), name = '', 
                        labels = expression(mu)) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", subtitle = expression("Población "~F), color = "") +
    theme_classic()

  samples <- data_frame(sample = 1:3) %>% 
    mutate(
      sims = rerun(3, rnormm(30, p = c(0.3, 0.7), mu = c(-2, 8), 
                             sigma = c(3.5, 3))), 
      x_bar = map_dbl(sims, mean))
  muestras_plot <- samples %>% 
    unnest(cols = c(sims)) %>% 
    ggplot(aes(x = sims)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_segment(aes(x = x_bar, xend = x_bar, y = 0, yend = 0.8), 
                 color = "blue") +
    xlim(-15, 20) +
    facet_wrap(~ sample) +
    scale_y_continuous(breaks = NULL) +
    geom_text(aes(x = x_bar, y = 0.95, label = "bar(x)"), parse = TRUE, 
              color = "blue", alpha = 0.2, hjust = 1) +
    labs(x = "", subtitle = "Muestras") +
    theme_classic() +
    theme(strip.background = element_blank(), strip.text.x = element_blank())

  samples_dist <- tibble(sample = 1:10000) %>% 
    mutate(sims = rerun(10000, rnormm(100, p = c(0.3, 0.7), mu = c(-2, 8), 
                                      sigma = c(3.5, 3))), 
           mu_hat = map_dbl(sims, mean))
  dist_muestral_plot <- ggplot(samples_dist, aes(x = mu_hat)) +
    geom_density(adjust = 2) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", y = "",
         subtitle = expression("Distribución muestral de "~hat(mu)==bar(X))) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    theme_classic()

  (pob_plot | plot_spacer()) / (muestras_plot | dist_muestral_plot) 
#+end_src

#+RESULTS:
[[file:../images/chihara-ejemplo.jpeg]]


#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/mundo-bootstrap.jpeg :exports results :results output graphics file
  dist_empirica <- tibble(id = 1:30, obs = samples$sims[[1]])

  dist_empirica_plot <- ggplot(dist_empirica, aes(x = obs)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    geom_vline(aes(xintercept = samples$x_bar[1], color = "x_bar"), 
               alpha = 0.8, linetype = "dashed") +
    xlim(-15, 20) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    labs(x = "", subtitle = expression("Distribución empírica"~hat(F))) +
    scale_colour_manual(values = c('mu' = 'red', 'x_bar' = 'blue'), name = '', 
                        labels = c(expression(mu), expression(bar(x)))) +
    scale_y_continuous(breaks = NULL) +
    theme_classic()

  samples_boot <- tibble(sample_boot = 1:3) %>% 
    mutate(
      sims_boot = rerun(3, sample(dist_empirica$obs, replace = TRUE)), 
      x_bar_boot = map_dbl(sims_boot, mean)
    )

  muestras_boot_plot <- samples_boot %>% 
    unnest(cols = c(sims_boot)) %>% 
    ggplot(aes(x = sims_boot)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(xintercept = samples$x_bar[1]), color = "blue",
               linetype = "dashed", alpha = 0.8) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_segment(aes(x = x_bar_boot, xend = x_bar_boot, y = 0, yend = 0.8), 
                 color = "black") +
    xlim(-15, 20) +
    facet_wrap(~ sample_boot) +
    geom_text(aes(x = x_bar_boot, y = 0.95, label = "bar(x)^'*'"), 
              parse = TRUE, color = "black", alpha = 0.3, hjust = 1) +
    labs(x = "", subtitle = "Muestras bootstrap") +
    scale_y_continuous(breaks = NULL) +
    theme_classic() +
    theme(strip.background = element_blank(), strip.text.x = element_blank())

  boot_dist <- data_frame(sample = 1:10000) %>% 
    mutate(
      sims_boot = rerun(10000, sample(dist_empirica$obs, replace = TRUE)), 
      mu_hat_star = map_dbl(sims_boot, mean))
  boot_muestral_plot <- ggplot(boot_dist, aes(x = mu_hat_star)) +
    geom_histogram(alpha = 0.5, fill = "darkgray", bins = 30) +
    labs(x = "", 
         subtitle = expression("Distribución bootstrap de "~hat(mu)^'*'==bar(X))) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_vline(aes(xintercept = samples$x_bar[1]), color = "blue", 
               linetype = "dashed", alpha = 0.8) +
    scale_y_continuous(breaks = NULL) +
    theme_classic()

  (dist_empirica_plot | plot_spacer()) / (muestras_boot_plot | boot_muestral_plot) 
#+end_src

#+RESULTS:
[[file:../images/mundo-bootstrap.jpeg]]

** Observación: 
Veremos ejemplos más complejos, pero nótese que si la muestra original son
observaciones independientes obtenidas de la distribución poblacional, entonces
logramos esto en las remuestras tomando observaciones con reemplazo de la
muestra. Igualmente, las remuestras deben ser del mismo tamaño que la muestra
original.

*** ~Ejercicio~:
- ¿Porqué no funcionaría tomar muestras sin reemplazo? Piensa si hay independencia
entre las observaciones de la remuestra, y cómo serían las remuestras sin reemplazo.
- ¿Por qué no se puede hacer bootstrap si no conocemos cómo se obtuvo la muestra original?


** Observación
Estos argumentos se pueden escribir con fórmulas usando por ejemplo la función
de distribución acumulada $F$ de la población y su estimador, que es la función
empírica $\hat{F}$, como en citep:Efron1993.  Si $\theta = t(F)$ es una cantidad
poblacional que queremos estimar, su estimador /plug-in/ es $\hat{\theta} =
t(\hat{F})$.

** Observación
La distribución empírica $\hat{F}$ es un estimador "razonable" de la
distribución poblacional $F,$ pues por el teorema de Glivenko-Cantelli
(citep:Wasserman2004, o [[https://en.wikipedia.org/wiki/Glivenko-Cantelli_theorem][aquí]]), $\hat{F}$ converge a $F$ cuando el tamaño de
muestra $n\to\infty$, lo cual es intuitivamente claro.

** Ejemplo 
En el siguiente ejemplo (tomadores de té), podemos estimar la proporción de
tomadores de té que prefiere el té negro usando nuestra muestra:

#+begin_src R :exports both :results none
  te <- read_csv("data/tea.csv") |>
    rowid_to_column() |>
    select(rowid, Tea, sugar)
#+end_src

#+begin_src R :exports both :results org 
  te |>
    mutate(negro = ifelse(Tea == "black", 1, 0)) |>
    summarise(prop_negro = mean(negro), n = length(negro), .groups = "drop")
#+end_src


#+RESULTS:
#+begin_src org
# A tibble: 1 × 2
  prop_negro     n
       <dbl> <int>
1      0.247   300
#+end_src

¿Cómo evaluamos la precisión de este estimador? Supondremos que el estudio se
hizo tomando una muestra aleatoria simple de tamaño 300 de la población de tomadores de té que
nos interesa. Podemos entonces usar el boostrap:

#+begin_src R :exports code :results none 
  ## paso 1: define el estimador
  calc_estimador <- function(datos){
    prop_negro <- datos |>
      mutate(negro = ifelse(Tea == "black", 1, 0)) |>
      summarise(prop_negro = mean(negro), n = length(negro), .groups = "drop") |>
      pull(prop_negro)
    prop_negro
  }  
#+end_src

#+begin_src R :exports code :results none 
  ## paso 2: define el proceso de remuestreo
  muestra_boot <- function(datos){
    ## tomar muestra con reemplazo del mismo tamaño
    sample_n(datos, size = nrow(datos), replace = TRUE)
  }  
#+end_src

#+begin_src R :exports code :results none 
  # paso 3: remuestrea y calcula el estimador
  prop_negro_tbl <- map_dbl(1:2000,  ~ calc_estimador(muestra_boot(datos = te))) %>%
    tibble(prop_negro = .)  
#+end_src

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-tea-mean.jpeg :exports results :results output graphics file
  ## paso 4: examina la distribución bootstrap
  prop_negro_tbl %>% 
    ggplot(aes(x = prop_negro)) +
    geom_histogram(bins = 15) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/bootstrap-tea-mean.jpeg]]

Y podemos evaluar varios aspectos, por ejemplo dónde está centrada y 
qué tan dispersa es la distribución bootstrap:

#+begin_src R :exports both :results org 
  prop_negro_tbl |>
    summarise(media = mean(prop_negro),
              sesgo = mean(prop_negro) - 0.2499,
              ee = sd(prop_negro),
              cuantil_75 = quantile(prop_negro, 0.75), 
              cuantil_25 = quantile(prop_negro, 0.25),
              .groups = "drop") |>
    mutate(across(where(is.numeric), round, 3)) |>
    pivot_longer(cols = everything())
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 5 × 2
  name        value
  <chr>       <dbl>
1 media       0.247
2 sesgo      -0.003
3 ee          0.025
4 cuantil_75  0.263
5 cuantil_25  0.23
#+end_src

* Propiedades distribución /bootstrap/ 

Uasremos la distribución /bootstrap/ principalmente para evaluar la variabilidad
de nuestros estimadores (y también otros aspectos como sesgo) estimando
la dispersión de la distribución de muestreo. Sin embargo, es importante notar
que no la usamos, por ejemplo, para saber dónde está centrada la distribución 
de muestreo, o para "mejorar" la estimación remuestreando.

** Ejemplo

En nuestro ejemplo, podemos ver varias muestras (por ejemplo 20) de tamaño 200, y
vemos cómo se ve la aproximación a la distribución de la población:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/distribucion-boostrap.jpeg :exports results :results output graphics file
  set.seed(911)
  muestras <- map(1:20, function(x) {
    muestra <- sample_n(poblacion_casas, 200, replace = T) |>
      mutate(rep = x, tipo = "muestras")}) |> bind_rows()
  dat_pob <- poblacion_casas |> mutate(tipo = "población", rep = 1)
  datos_sim <- bind_rows(dat_pob, muestras)

  ggplot(datos_sim, aes(sample = precio_miles, group = interaction(tipo, rep))) + 
    geom_qq(distribution = stats::qunif, alpha = 0.7, size = 0.5, geom = "line") + 
    geom_qq(data = dat_pob, aes(sample = precio_miles), colour = "red", size = 1,
            distribution = stats::qunif, geom="point") +
    scale_y_log10(breaks = c(50, 100, 200, 400, 800)) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/distribucion-boostrap.jpeg]]


Podemos calcular las distribuciones de remuestreo para cada muestra bootstrap,
y compararlas con la distribución de muestreo real.

#+begin_src R :exports code :results none 
  ## paso 1: define el estimador
  calc_estimador <- function(datos){
    media_precio <- datos %>% 
      summarise(media = mean(precio_miles), .groups = "drop") %>% 
      pull(media)
    media_precio
  }
#+end_src

#+begin_src R :exports code :results none 
  ## paso 2: define el proceso de remuestreo
  muestra_boot <- function(datos, n = NULL){
    ## tomar muestra con reemplazo del mismo tamaño
    if(is.null(n)){
      m <- sample_n(datos, size = nrow(datos), replace = TRUE)}
    else {
        m <- sample_n(datos, size = n, replace = TRUE)
      }
    m
  }
#+end_src

#+begin_src R :exports code :results none :eval never
  dist_boot <- datos_sim |>
    filter(tipo == "muestras") |>
    select(precio_miles, rep) |> 
    group_by(rep) |> nest() |> 
    mutate(precio_miles =  map(data, function(data){
      tibble(precio_miles = map_dbl(1:1000, ~ calc_estimador(muestra_boot(data))))
    })) |>
    select(rep, precio_miles) |>
    unnest()
#+end_src

#+begin_src R :exports code :results none :eval never
  dist_muestreo <- datos_sim |>
    filter(tipo == "población") |>
    group_by(rep) |> nest() |>
    mutate(precio_miles =  map(data, function(data){
      tibble(precio_miles = map_dbl(1:1000, ~ calc_estimador(muestra_boot(data, n = 200))))
    })) |>
    select(rep, precio_miles) |>
    unnest()
#+end_src

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/distribucion-bootstrap.jpeg :exports results :results output graphics file
  ggplot(dist_boot, aes(sample = precio_miles, group = interaction(rep))) + 
    geom_qq(distribution = stats::qunif, size = 0.1, alpha = 0.1) + 
    geom_qq(data = dist_muestreo, aes(sample = precio_miles), colour = "red",
            distribution = stats::qunif, alpha = 0.1) +
    ylim(c(125, 230)) + sin_lineas + 
    labs(subtitle = "Estimaciones de distribución \n de muestreo (media)")
#+end_src

#+RESULTS:
[[file:../images/distribucion-bootstrap.jpeg]]

Obsérvese que:

- En algunos casos la aproximación es mejor que en otros (a veces
la muestra tiene valores ligeramente más altos o más bajos). 
- La dispersión de cada una de estas distribuciones bootstrap es similar a la de la verdadera
distribución de muestreo (en rojo), pero puede está desplazada dependiendo
de la muestra original que utilizamos.
- Adicionalmente, los valores centrales de la distribución de bootstrap
tiende cubrir el verdadero valor que buscamos estimar, que es:

#+begin_src R :exports both :results org 
  poblacion_casas |>
    summarise(media = mean(precio_miles), .groups = "drop")  
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 1
  media
  <dbl>
1  183.
#+end_src


** Variación en distribución /bootstrap/

En el proceso de estimación bootstrap hay dos fuentes de variación pues:

- La muestra original se selecciona con aleatoriedad de una población.
- Las muestras /bootstrap/ se seleccionan con aleatoriedad de la muestra 
original. Esto es, la estimación bootstrap ideal es un resultado asintótico
$B=\infty$, en esta caso $\hat{\textsf{ee}}_B$ iguala la estimación /plug-in/
$\mathsf{ee}_{P_n}$.

En el proceso de *bootstrap* podemos controlar la variación del segundo aspecto,
conocida como *implementación de muestreo Monte Carlo*, y la variación Monte Carlo
decrece conforme incrementamos el número de muestras.

Podemos eliminar la variación Monte Carlo si seleccionamos todas las posibles
muestras con reemplazo de tamaño $n$, hay ${2n-1}\choose{n}$ posibles muestras y
si seleccionamos todas obtenemos $\hat{\textsf{ee}}_\infty$ (bootstrap ideal),
sin embargo, en la mayor parte de los problemas no es factible proceder así.

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-variacion.jpeg  :exports results :results output graphics file :eval never :tangle no
  set.seed(8098)
  pob_plot <- ggplot(data_frame(x = -15:20), aes(x)) +
    stat_function(fun = dnormm, args = list(p = c(0.3, 0.7), mu = c(-2, 8), 
                                            sigma = c(3.5, 3)), alpha = 0.8) +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    scale_colour_manual(values = c('mu' = 'red'), name = '', 
                        labels = expression(mu)) +
    labs(x = "", y = "", subtitle = "Población", color = "") +
    theme(axis.text.y = element_blank())

  samples <- data_frame(sample = 1:6) %>% 
    mutate(
      sims = rerun(6, rnormm(50, p = c(0.3, 0.7), mu = c(-2, 8), 
                             sigma = c(3.5, 3))), 
      x_bar = map_dbl(sims, mean))

  means_boot <- function(n, sims) {
    rerun(n, mean(sample(sims, replace = TRUE))) %>%
      flatten_dbl()
  }
  samples_boot <- samples %>% 
    mutate(
      medias_boot_30_1 = map(sims, ~means_boot(n = 30, .)), 
      medias_boot_30_2 = map(sims, ~means_boot(n = 30, .)), 
      medias_boot_1000_1 = map(sims, ~means_boot(n = 1000, .)), 
      medias_boot_1000_2 = map(sims, ~means_boot(n = 1000, .))
    )

  emp_dists <- samples_boot %>% 
    unnest(cols = sims) %>% 
    rename(obs = sims)
  emp_dists_plots <- ggplot(emp_dists, aes(x = obs)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5, 
               show.legend = FALSE) +
    geom_vline(aes(xintercept = x_bar, color = "x_bar"), show.legend = FALSE, 
               alpha = 0.8, linetype = "dashed") +
    xlim(-15, 20) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    labs(x = "", y = "", subtitle = expression("Distribución empírica"~P[n])) +
    scale_colour_manual(values = c('mu' = 'red', 'x_bar' = 'blue'), name = '', 
                        labels = c(expression(mu), expression(bar(x)))) +
    facet_wrap(~ sample, ncol = 1) +
    theme(strip.background = element_blank(), strip.text.x = element_blank(), 
          axis.text.y = element_blank())

  boot_dists_30 <- samples_boot %>% 
    unnest(cols = c(medias_boot_30_1, medias_boot_30_2)) %>% 
    pivot_longer(cols = c(medias_boot_30_1, medias_boot_30_2), 
                 values_to = "mu_hat_star", names_to = "boot_trial",
                 names_prefix = "medias_boot_30_")
  boot_dists_30_plot <- ggplot(boot_dists_30, aes(x = mu_hat_star)) +
    geom_histogram(alpha = 0.5, fill = "darkgray") +
    labs(x = "", y = "",
         subtitle = expression("Distribución bootstrap B = 30")) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_vline(aes(xintercept = x_bar), color = "blue", 
               linetype = "dashed", alpha = 0.8) +
    facet_grid(sample~boot_trial) +
    theme(strip.background = element_blank(), strip.text.y = element_blank(), 
          axis.text.y = element_blank())

  boot_dists_1000 <- samples_boot %>% 
    unnest(cols = c(medias_boot_1000_1, medias_boot_1000_2)) %>% 
    pivot_longer(cols = c(medias_boot_1000_1, medias_boot_1000_2), 
                 values_to = "mu_hat_star", names_to = "boot_trial",
                 names_prefix = "medias_boot_1000_")
  boot_dists_1000_plot <- ggplot(boot_dists_1000, aes(x = mu_hat_star)) +
    geom_histogram(alpha = 0.5, fill = "darkgray") +
    labs(subtitle = expression("Distribución bootstrap B = 1000"), 
         x = "", y = "") +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_vline(aes(xintercept = x_bar), color = "blue", 
               linetype = "dashed", alpha = 0.8) +
    facet_grid(sample~boot_trial) +
    scale_colour_manual(values = c('mu' = 'red', 'x_bar' = 'blue'), name = '',
                        labels = c(expression(mu), expression(bar(x)))) +
    theme(strip.background = element_blank(), strip.text.y = element_blank(), 
          strip.text.x = element_blank(), axis.text.y = element_blank())

  (pob_plot | plot_spacer() | plot_spacer()) /
    (emp_dists_plots | boot_dists_30_plot | boot_dists_1000_plot) +
    plot_layout(heights = c(1, 5), "cm")
#+end_src

En la siguiente gráfica mostramos 6 posibles muestras de tamaño 50 simuladas de
la población, para cada una de ellas se graficó la distribución empírica y se
se realizan histogramas de la distribución bootstrap con $B=30$ y $B=1000$, en 
cada caso hacemos dos repeticiones, notemos que cuando el número de muestras 
bootstrap es grande las distribuciones bootstrap son muy similares (para una 
muestra de la población dada), esto es porque disminuimos el erro Monte Carlo. 
También vale la pena recalcar que la distribución bootstrap está centrada en el 
valor observado en la muestra (línea azúl punteada) y no en el valor poblacional
sin embargo la forma de la distribución es similar a lo largo de las filas.

#+attr_html: :width 700 :align center
file:images/bootstrap_mc_error.png

Entonces, ¿cuántas muestras bootstrap? 

1. Incluso un número chico de replicaciones bootstrap, digamos $B=25$ es
   informativo, y $B=50$ con frecuencia es suficiente para dar una buena
   estimación de $\mathsf{ee}_P(\hat{\theta})$ (citep:Efron1993).

2. Cuando se busca estimar error estándar (citep:Chihara2018) recomienda $B=1000$
   muestras, o $B=10,000$ muestras dependiendo la precisión que se busque.

* Error estándar /bootstrap/ e intervalos normales 

Ahora podemos construir nuestra primera versión de intervalos de confianza
basados en la distribución bootstrap.

- Supongamos que queremos estimar una cantidad poblacional $\theta$ con una
  estadística $\hat{\theta} = t(X_1,\ldots, X_n)$, donde $X_1,\ldots, X_n$ es
  una muestra independiente e idénticamente distribuida de la población.

- Suponemos además que la distribución muestral de $\hat{\theta}$ es
  aproximadamente normal (el teorema central del límite aplica), y está centrada
  en el verdadero valor poblacional $\theta$.

Ahora queremos construir un intervalo que tenga probabilidad 95\% de cubrir al
valor poblacional $\theta$. Tenemos que
\begin{align}
P(-2\mathsf{ee}(\hat{\theta}) < \hat{\theta} - \theta < 2\mathsf{ee}(\hat{\theta})) \approx 0.95\,,
\end{align}
por las propiedades de la distribución normal ($P(-2\sigma < X -\mu <
2\sigma)\approx 0.95$ si $X$ es normal con media $\mu$ y desviación estándar
$\sigma$). Entonces
\begin{align}
P(\hat{\theta} - 2\mathsf{ee}(\hat{\theta}) < \theta < \hat{\theta} + 2\mathsf{ee}(\hat{\theta})) \approx 0.95\,.
\end{align}
Es decir, la probabilidad de que el verdadero valor poblacional $\theta$ esté en el intervalo
$$[\hat{\theta} - 2\mathsf{ee}(\hat{\theta}), \hat{\theta} + 2\mathsf{ee}(\hat{\theta})]$$
es cercano a 0.95. En este intervalo no conocemos el error estándar (es la desviación estándar
de la distribución de muestreo de $\hat{\theta}$), y aquí es donde
entre la distribución bootstrap, que aproxima la distribución de muestreo. Lo estimamos con
\begin{align}
\hat{\mathsf{ee}}_{\textrm{boot}}(\hat{\theta})\,,
\end{align}
que es la desviación estándar de la *distribución bootsrap*.

*** ~Definición~:
El *error estándar bootstrap* $\hat{\mathsf{ee}}_{\textrm{boot}}(\hat{\theta})$ se
define como la desviación estándar de la distribución bootstrap de $\theta$. El
*intervalo de confianza normal bootstrap* al $95\%$ está dado por
\begin{align}
[\hat{\theta} -
2\mathsf{ee}(\hat{\theta}), \hat{\theta} + 2\mathsf{ee}(\hat{\theta})]\,.
\end{align}
  
Nótese que hay varias cosas qué checar aquí: que el teorema central del límite aplica y
que la distribución de muestreo de nuestro estimador está centrado en el valor verdadero.
Esto en algunos casos se puede demostrar usando la teoría, pero más abajo veremos
comprobaciones empíricas.


** Ejemplo

Consideremos la estimación que hicimos de el procentaje de tomadores de té que
toma té negro:

#+begin_src R :exports both :results org 
  ## paso 1: define el estimador
  calc_estimador <- function(datos){
    prop_negro <- datos %>% 
      mutate(negro = ifelse(Tea == "black", 1, 0)) %>% 
      summarise(prop_negro = mean(negro), n = length(negro)) %>% 
      pull(prop_negro)
    prop_negro
  }
  prop_hat <- calc_estimador(te)
  prop_hat %>% round(2)
#+END_SRC

#+RESULTS:
#+begin_src org
[1] 0.25
#+end_src

Podemos graficar su distribución bootstrap ---la cual simulamos arriba---.

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/distirbucion-bs-te-negro.jpeg :exports results :results output graphics file
  g_hist <- ggplot(prop_negro_tbl, aes(x = prop_negro)) + geom_histogram(bins = 15) + sin_lineas
  g_qq_normal <- ggplot(prop_negro_tbl, aes(sample = prop_negro)) +
    geom_qq() + geom_qq_line(colour = "red") + sin_lineas
  g_hist + g_qq_normal
#+end_src

#+RESULTS:
[[file:../images/distirbucion-bs-te-negro.jpeg]]

Y notamos que la distribución /bootstrap/ es aproximadamente normal. 
Adicionalmente, vemos que el sesgo tiene un valor estimado de:

#+begin_src R :exports both :results org 
  media_boot <- prop_negro_tbl %>% pull(prop_negro) %>% mean
  media_boot - prop_hat
#+end_src

#+RESULTS:
#+begin_src org
[1] -0.0002133
#+end_src

De esta forma, hemos verificado que:

- La distribución /bootstrap/ es aproximadamente normal (ver gráfica de cuantiles normales); 
- La distribución /bootstrap/ es aproximadamente insesgada.

Lo cual nos lleva a construir intervalos de confianza basados en la distribución
normal. Estimamos el error estándar con la desviación estándar de la
distribución /bootstrap/

#+begin_src R :exports both :results org 
ee_boot <- prop_negro_tbl %>% pull(prop_negro) %>% sd
ee_boot
#+end_src

#+RESULTS:
#+begin_src org
[1] 0.02454
#+end_src

y construimos un intervalo de confianza del $95\%$:

#+begin_src R :exports both :results org 
  intervalo_95 <- c(prop_hat - 2 * ee_boot, prop_hat + 2 * ee_boot)
  intervalo_95 %>% round(3)
#+end_src

#+RESULTS:
#+begin_src org
[1] 0.198 0.296
#+end_src

Este intervalo tiene probabilidad del $95\%$ de capturar al verdadero poblacional.

* Inventarios de casas vendidas                                      

Ahora consideremos el problema de estimar el total del valor de las casas
vendidas en un periodo. Tenemos una muestra de tamaño $n=150$:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-bootstrap-intervalos.jpeg :exports results :results output graphics file
  ## muestra original
  set.seed(121)
  muestra_casas <- sample_n(poblacion_casas, size = 150)
  ## paso 1: define el estimador
  calc_estimador_casas <- function(datos){
    N <- nrow(poblacion_casas)
    n <- nrow(datos)
    total_muestra <- sum(datos$precio_miles)
    estimador_total <- (N / n) * total_muestra
    estimador_total
  }
  ## paso 2: define el proceso de remuestreo
  muestra_boot <- function(datos){
    ## tomar muestra con reemplazo del mismo tamaño
    sample_n(datos, size = nrow(datos), replace = TRUE)
  }
  ## paso 3: remuestrea y calcula el estimador
  totales_boot <- map_dbl(1:5000,  ~ calc_estimador_casas(muestra_boot(muestra_casas))) %>% 
    tibble(total_boot = .)
  ## paso 4: examina la distribución bootstrap
  g_hist <- totales_boot %>% 
    ggplot(aes(x = total_boot)) +
    geom_histogram() + sin_lineas +
    geom_vline(xintercept = quantile(totales_boot$total_boot, 0.975), colour = "gray") +
    geom_vline(xintercept = quantile(totales_boot$total_boot, 0.025), colour = "gray")
  g_qq <- totales_boot %>%
    ggplot(aes(sample = total_boot)) +
    geom_qq() + geom_qq_line(colour = "red") +
    geom_hline(yintercept = quantile(totales_boot$total_boot, 0.975), colour = "gray") +
    geom_hline(yintercept = quantile(totales_boot$total_boot, 0.025), colour = "gray") +
    sin_lineas
  g_hist + g_qq
#+end_src

#+RESULTS:
[[file:../images/casas-bootstrap-intervalos.jpeg]]

En este caso, distribución de muestreo presenta cierta asimetría, pero la
desviación no es grande. En la parte central la aproximación normal es
razonable. Procedemos a checar sesgo

#+begin_src R :exports both :results org 
  total_est <- calc_estimador_casas(muestra_casas)
  sesgo <- mean(totales_boot$total_boot) - total_est
  sesgo
#+end_src

#+RESULTS:
#+begin_src org
[1] 110.1
#+end_src

Este número puede parecer grande, pero sí calculamos la desviación relativa
con respecto al estimador vemos que es chico en la escala de la distribución 
bootstrap:

#+begin_src R :exports both :results org 
  sesgo_relativo <- sesgo / total_est
  sesgo_relativo
#+end_src

#+RESULTS:
#+begin_src org
[1] 0.0005054
#+end_src

De forma que procedemos a construir intervalos de confianza como sigue :
#+begin_src R :exports both :results org 
  ee_boot <- sd(totales_boot$total_boot)
  c(total_est - 2*ee_boot, total_est + 2*ee_boot)  
#+end_src

Que está en miles de dólares. En millones de dólares, este intervalo es:

#+begin_src R :exports both :results org 
  intervalo_total <- c(total_est - 2*ee_boot, total_est + 2*ee_boot) / 1000
  intervalo_total |> round(4)
#+end_src

#+RESULTS:
#+begin_src org
[1] 217.8 217.8
#+end_src

*** ~Nota~:
en este ejemplo mostraremos una alternativa de intervalos de confianza que es
más apropiado cuando observamos asimetría. Sin embargo, primero tendremos que
hablar de dos conceptos clave con respecto a intervalos de confianza:
calibración e interpretación.

* Calibración de intervalos de confianza

¿Cómo sabemos que nuestros intervalos de confianza del $95\%$ nominal 
tienen cobertura real de $95\%$? Es decir, tenemos que checar:

- El procedimiento para construir intervalos debe dar intervalos tales
que el valor poblacional está en el intervalo de confianza para 95% de las muestras.

Como solo tenemos una muestra, la calibración depende de argumentos teóricos o
estudios de simulación previos. Para nuestro ejemplo de casas tenemos la
población, así que podemos checar qué cobertura real tienen los intervalos normales:

#+begin_src R :exports none :results none :eval never
  simular_intervalos <- function(rep, size = 150){
    muestra_casas <- sample_n(poblacion_casas, size = size)
    N <- nrow(poblacion_casas)
    n <- nrow(muestra_casas)
    total_est <- (N / n) * sum(muestra_casas$precio_miles)
    ## paso 1: define el estimador
    calc_estimador_casas <- function(datos){
      total_muestra <- sum(datos$precio_miles)
      estimador_total <- (N / n) * total_muestra
      estimador_total
    }
    ## paso 2: define el proceso de remuestreo
    muestra_boot <- function(datos){
      ## tomar muestra con reemplazo del mismo tamaño
      sample_n(datos, size = nrow(datos), replace = TRUE)
    }
    ## paso 3: remuestrea y calcula el estimador
    totales_boot <- map_dbl(1:2000,  ~ calc_estimador_casas(muestra_boot(muestra_casas))) %>% 
      tibble(total_boot = .) %>%
      summarise(ee_boot = sd(total_boot)) %>% 
      mutate(inf = total_est - 2*ee_boot, sup = total_est + 2*ee_boot) %>% 
      mutate(rep = rep)
    totales_boot
  }
  ## Para recrear, correr:
  sims_intervalos <- map(1:100, ~ simular_intervalos(rep = .x))
  write_rds(sims_intervalos, "cache/sims_intervalos.rds")
#+end_src

#+begin_src R :exports none :results none 
  ## Para usar resultados en cache:
  sims_intervalos <- read_rds("cache/sims_intervalos.rds")
#+end_src


#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-estimacion-intervalos.jpeg :exports results :results output graphics file
  total <- sum(poblacion_casas$precio_miles)
  sims_tbl <- sims_intervalos %>% 
    bind_rows %>%
    mutate(cubre = inf < total & total < sup) 
  ggplot(sims_tbl, aes(x = rep)) +
    geom_hline(yintercept = total, colour = "red") +
    geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre)) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/casas-estimacion-intervaloes.jpeg]]

La cobertura para estos 100 intervalos simulados da

#+begin_src R :exports both :results org 
  total <- sum(poblacion_casas$precio_miles)
  sims_tbl %>% 
    summarise(cobertura = mean(cubre))  
#+end_src

que es *consistente* con una cobertura real del $95\%$ (¿qué significa
"consistente"? ¿Cómo puedes checarlo con el /bootstrap/?)

*** ~Observación~:
En este caso teníamos la población real, y pudimos verificar la cobertura de
nuestros intervalos. En general no la tenemos. Estos ejercicios de simulación se
pueden hacer con poblaciones sintéticas que se generen con las características
que creemos va a tener nuestra población (por ejemplo, sesgo, colas largas,
etc.).

#+BEGIN_NOTES
En general, no importa qué tipo de estimadores o intervalos de confianza usemos,
requerimos checar la calibración. Esto puede hacerse con ejercicios de
simulación con poblaciones sintéticas y tanto los procedimientos de muestreo
como los tamaños de muestra que nos interesa usar.
#+END_NOTES

Verificar la cobertura de nuestros intervalos de confianza por medio simulación está
bien estudiado para algunos casos. Por ejemplo, cuando trabajamos con estimaciones para 
poblaciones teóricas. En general sabemos que los procedimientos funcionan bien en casos: 
- con distribuciones simétricas que tengan colas no muy largas; 
- estimación de proporciones donde no tratamos con casos raros o casos seguros
  (probabilidades cercanas a 0 o 1).

* Interpretación intervalos de confianza

Como hemos visto, "intervalo de confianza" (de $90\%$ de confianza, por ejemplo)
es un término *frecuentista*, que significa:

- *Cada muestra produce un intervalo distinto*. Para el $90\%$ de las muestras
  posibles, el intervalo cubre al valor poblacional.
- La afirmación es *sobre el intervalo y el mecanismo para construirlo.*
- Así que con *alta probabilidad*, el intervalo contiene el valor poblacional.
- Intervalos más anchos nos dan más incertidumbre acerca de dónde está el
  verdadero valor poblacional (y al revés para intervalos más angostos).

Existen también "intervalos de credibilidad" (de $90\%$ de probabilidad, por
ejemplo), que se interpetan de forma *bayesiana*:

- Con $90\%$ de probabilidad (relativamente alta), creemos que el valor
  poblacional está dentro del intervalo de credibilidad.

Esta última interpretación es más natural. Obsérvese que para hablar de
intervalos de confianza frecuentista tenemos que decir:

- Este intervalo particular cubre o no al verdadero valor, pero nuestro
  procedimiento produce intervalos que contiene el verdadero valor para el $90\%$ de las muestras. 
- Esta es una interpretación relativamente débil, y muchos intervalos poco útiles pueden satisfacerla.
- La interpretación bayesiana es más natural porque expresa más claramente
  incertidumbre acerca del valor poblacional.

Sin embargo,

- La interpretación frecuentista nos da maneras empíricas de probar si los
  intervalos de confianza están bien calibrados o no: es un mínimo que
  "intervalos del $90\%$" deberían satisfacer.

Así que tomamos el punto de vista bayesiano en la intepretación, pero buscamos
que nuestros intervalos cumplan o aproximen bien garantías frecuentistas
(discutimos esto más adelante). Los intervalos que producimos en esta sección
pueden interpretarse de las dos maneras.

* Intervalos /bootstrap/ de percentiles

Retomemos nuestro ejemplo del valor total del precio de las casas. A través de
remuestras bootstrap hemos verificado gráficamente que la distribución de
remuestreo es *ligeramente* asimétrica (ver la figura de abajo). 

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-histograma.jpeg :exports results :results output graphics file
  g_hist2 <- totales_boot %>% 
    ggplot(aes(x = total_boot)) +
    geom_histogram(aes(y = ..density..)) + 
    stat_function(fun = dnorm, args = list(mean = total_est, sd = ee_boot), color = 'red', lty = 2) +
    sin_lineas

  g_hist2 + g_qq
#+end_src

#+RESULTS:
[[file:../images/casas-histograma.jpeg]]

Anteriormente hemos calculado intervalos de confianza basados en supuestos
normales por medio del error éstandar. Este intervalo está dado por

#+begin_src R :exports both :results org 
  intervalo_total %>% round(1)  
#+end_src

#+RESULTS:
#+begin_src org
[1] 203.4 232.3
#+end_src

y por construcción sabemos que es simétrico con respecto al valor estimado, pero 
como podemos ver la distribución de muestreo no es simétrica, lo cual podemos
confirmar por ejemplo calculando el porcentaje de muestras bootstrap que caen
por arriba y por debajo del intervalo construido:

#+begin_src R :exports both :results org 
  totales_boot %>% 
    mutate(upper = total_boot >= max(intervalo_total * 1000), 
           lower = total_boot <= min(intervalo_total * 1000)) %>% 
    summarise(prop_inf = mean(lower), 
              prop_sup = mean(upper))
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 2
  prop_inf prop_sup
     <dbl>    <dbl>
1   0.0192    0.026
#+end_src

los cuales se han calculado como el porcentaje de medias bootstrap por debajo
(arriba) de la cota inferior (superior), y vemos que no coinciden con el nivel de 
confianza prestablecido ($2.5\%$ para cada extremo).

Otra opción común que se usa específicamente cuando la distribución bootstrap 
no es muy cercana a la normal son los intervalos de percentiles bootstrap:

*** ~Definición~:
El *intervalo de percentiles bootstrap* al $95\%$ de confianza está dado por
\begin{align}
[q_{0.025}, q_{0.975}]\,,
\end{align}
donde $q_f$ es el percentil $f$ de la distribución bootstrap.


Otros intervalos comunes son el de $80\%$ o $90\%$ de confianza, por ejemplo,
que corresponden a $[q_{0.10}, q_{0.90}]$ y $[q_{0.05}, q_{0.95}]$. *Ojo*:
intervalos de confianza muy alta (por ejemplo $99.5\%$) pueden tener mala
calibración o ser muy variables en su longitud pues dependen del comportamiento
en las colas de la distribución.

Para el ejemplo de las casas, calcularíamos simplemente

#+begin_src R :exports both :results org 
  intervalo_95 <- totales_boot %>% pull(total_boot) %>% quantile(., probs = c(0.025, 0.975)) / 1000
  (intervalo_95) %>% round(1)
#+end_src

#+RESULTS:
#+begin_src org
 2.5% 97.5% 
204.3 232.5
#+end_src

que está en millones de dólares. Nótese que es similar al intervalo de error estándar.

Otro punto interesante sobre los intervalos /bootstrap/ de percentiles es que
lidian naturalmente con la asímetría de la distribución bootstrap. Ilustramos
esto con la distancia de las extremos del intervalo con respecto a la media:

#+begin_src R :exports both :results org 
  abs(intervalo_95 - total_est/1000)  
#+end_src

#+RESULTS:
#+begin_src org
  2.5%  97.5% 
13.539 14.647
#+end_src

Los intervalos de confianza nos permiten presentar un rango de valores posibles
para el parámetro de interés. Esto es una notable diferencia con respecto a
presentar sólo un candidato como estimador. Nuestra fuente de información son
los datos. Es por esto que si vemos valores muy chicos (grandes) en nuestra
muestra, el intervalo se tiene que extender a la izquierda (derecha) para
compensar dichas observaciones.

*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:
Explica por qué cuando la aproximación normal es apropiada, el intervalo de
percentiles al 95% es muy similar al intervalo normal de 2 errores estándar.

** Ejemplo 

Consideramos los datos de propinas. Queremos estimar la media de cuentas
totales para la comida y la cena. Podemos hacer bootstrap de cada grupo
por separado:

#+begin_src R :exports both :results org
  ## en este ejemplo usamos rsample, pero puedes escribir tu propio código
  library(rsample)
  propinas <- read_csv("data/propinas.csv", progress = FALSE)
  propinas
#+end_src

#+RESULTS:
#+begin_src org
Rows: 244 Columns: 6
── Column specification ──────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (3): fumador, dia, momento
dbl (3): cuenta_total, propina, num_personas

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
# A tibble: 244 × 6
   cuenta_total propina fumador dia   momento num_personas
          <dbl>   <dbl> <chr>   <chr> <chr>          <dbl>
 1        17.0     1.01 No      Dom   Cena               2
 2        10.3     1.66 No      Dom   Cena               3
 3        21.0     3.5  No      Dom   Cena               3
 4        23.7     3.31 No      Dom   Cena               2
 5        24.6     3.61 No      Dom   Cena               4
 6        25.3     4.71 No      Dom   Cena               4
 7         8.77    2    No      Dom   Cena               2
 8        26.9     3.12 No      Dom   Cena               4
 9        15.0     1.96 No      Dom   Cena               2
10        14.8     3.23 No      Dom   Cena               2
# … with 234 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src


#+begin_src R :exports both :results org 
  estimador <- function(split, ...){
    muestra <- analysis(split) |> group_by(momento)
    muestra |>
      summarise(estimate = mean(cuenta_total), .groups = 'drop') |>
      mutate(term = momento)
  }
  intervalo_propinas_90 <- bootstraps(propinas, strata = momento, 1000) |>
    mutate(res_boot = map(splits, estimador)) |>
    int_pctl(res_boot, alpha = 0.10) |> 
    mutate(across(where(is.numeric), round, 2))
  intervalo_propinas_90
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 2 × 6
  term   .lower .estimate .upper .alpha .method   
  <chr>   <dbl>     <dbl>  <dbl>  <dbl> <chr>     
1 Cena     19.7      20.8   22.0    0.1 percentile
2 Comida   15.6      17.2   18.7    0.1 percentile
#+end_src

Nota: ~.estimate~ es la media de los valores de la estadística sobre las
remuestras, *no* es el estimador original.

De la tabla anterior inferimos que la media en la cuenta en la cena es más
grande que la de la comida.  Podemos graficar agregando los estimadores /plug-in/:

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/propinas-bootstrap.jpeg :exports results :results output graphics file
  estimadores <- propinas %>% 
    group_by(momento) %>% 
    rename(term = momento) %>% 
    summarise(media = mean(cuenta_total))

  ggplot(intervalo_propinas_90, aes(x = term)) +
    geom_linerange(aes(ymin = .lower, ymax = .upper)) +
    geom_point(data = estimadores, aes(y = media), colour = "red", size = 3) +
    xlab("Momento") + ylab("Media de cuenta total (dólares)") +
    labs(subtitle = "Intervalos de 90% para la media") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/propinas-bootstrap.jpeg]]

Nótese que el /bootstrap/ lo hicimos por separado en cada momento del día (por eso
el argumento ~strata~ en la llamada a *bootstraps*):


*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:
Justifica el procedimiento de hacer el /bootstrap/ separado para cada grupo. ¿Qué supuestos
acerca del muestreo se deben satisfacer? ¿Deben ser muestras aleatorias simples 
de cada momento del día, por ejemplo? ¿Qué harías si no fuera así, por ejemplo, si 
se escogieron al azar tickets de todos los disponibles en un periodo?

* /Boostrap/ y otras estadísticas


El /bootstrap/ es una técnica versátil. Un ejemplo son *estimadores de razón*, que
tienen la forma
\begin{align}
\hat{r} = \frac{\overline y}{\overline x}\,.
\end{align}

Por ejemplo, ¿cómo haríamos estimación para el procentaje de área area habitable
de las casas en relación al tamaño del lote? Una manera de estimar esta cantidad
es dividiendo la suma del área habitable de nuestra muestra y dividirlo entre
la suma del área de los lotes de nuestra muestra, como en la fórmula anterior. Esta
fórmula es más difícil pues tanto numerador como denominador tienen variabilidad,
y estas dos cantidades no varían independientemente.

Con el /bootstrap/ podemos atacar estos problemas.

** Estimadores de razón

Nuestra muestra original es:

#+begin_src R :exports both :results org 
  set.seed(250)
  casas_muestra <- sample_n(poblacion_casas, 200)
  casas_muestra |> as.data.frame() |> str()
#+end_src

#+RESULTS:
#+begin_src org
'data.frame':	200 obs. of  46 variables:
 $ id                   : num  1166 855 579 1158 882 ...
 $ tipo_zona            : chr  "RL" "RL" "FV" "RL" ...
 $ frente_lote          : num  79 102 34 34 44 81 70 78 64 61 ...
 $ calle                : chr  "Pave" "Pave" "Pave" "Pave" ...
 $ forma_lote           : chr  "IR1" "Reg" "Reg" "IR1" ...
 $ nombre_zona          : chr  "NridgHt" "Sawyer" "Somerst" "NridgHt" ...
 $ tipo_edificio        : chr  "1Fam" "1Fam" "TwnhsE" "Twnhs" ...
 $ estilo               : chr  "1Story" "1Story" "2Story" "1Story" ...
 $ calidad_gral         : num  7 5 7 7 7 6 5 6 6 5 ...
 $ condicion_gral       : num  5 4 5 5 5 5 5 6 5 7 ...
 $ año_construccion     : num  2009 1955 2007 2007 1990 ...
 $ calidad_exteriores   : chr  "Gd" "TA" "Gd" "Gd" ...
 $ material_exteriores  : chr  "VinylSd" "Wd Sdng" "VinylSd" "VinylSd" ...
 $ condicion_exteriores : chr  "TA" "TA" "TA" "TA" ...
 $ calidad_sotano       : chr  "Gd" "TA" "Gd" "Gd" ...
 $ condicion_sotano     : chr  "TA" "TA" "TA" "TA" ...
 $ tipo_sotano          : chr  "Unf" "ALQ" "Unf" "GLQ" ...
 $ calefaccion          : chr  "GasA" "GasA" "GasA" "GasA" ...
 $ calidad_calefaccion  : chr  "Ex" "TA" "Ex" "Ex" ...
 $ aire_acondicionado   : chr  "Y" "Y" "Y" "Y" ...
 $ baños_completos      : num  2 1 2 2 2 1 1 2 2 2 ...
 $ baños_medios         : num  0 1 0 0 1 0 0 0 1 0 ...
 $ recamaras_sup        : num  3 3 2 2 3 3 3 3 3 3 ...
 $ calidad_cocina       : chr  "Gd" "TA" "Gd" "Gd" ...
 $ cuartos_sup          : num  7 6 5 6 7 5 6 7 7 5 ...
 $ tipo_garage          : chr  "Attchd" "Attchd" "Detchd" "Attchd" ...
 $ terminado_garage     : chr  "RFn" "Unf" "Unf" "RFn" ...
 $ num_coches           : num  2 2 2 2 2 0 0 2 2 2 ...
 $ calidad_garage       : chr  "TA" "TA" "TA" "TA" ...
 $ condicion_garage     : chr  "TA" "TA" "TA" "TA" ...
 $ año_venta            : num  2009 2006 2008 2009 2007 ...
 $ mes_venta            : num  9 7 2 7 4 5 12 6 2 9 ...
 $ tipo_venta           : chr  "New" "WD" "WD" "WD" ...
 $ condicion_venta      : chr  "Partial" "Abnorml" "Abnorml" "Normal" ...
 $ lat                  : num  42.1 42 42.1 42.1 42 ...
 $ long                 : num  -93.7 -93.7 -93.6 -93.7 -93.6 ...
 $ area_sotano_m2       : num  140 164 64 122 107 ...
 $ area_1er_piso_m2     : num  139.5 165.3 65.3 122.1 110.3 ...
 $ area_2o_piso_m2      : num  0 0 64 0 49.2 ...
 $ area_habitable_sup_m2: num  140 165 129 122 160 ...
 $ area_garage_m2       : num  59.8 42.2 50.2 58.2 37.2 ...
 $ area_lote_m2         : num  886 1665 335 465 1278 ...
 $ precio_miles         : num  233 170 146 230 188 ...
 $ valor_misc_miles     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ precio_m2_miles      : num  1.67 1.03 1.13 1.88 1.18 ...
 $ precio_m2            : num  1671 1029 1129 1884 1175 ...
#+end_src

El estimador de interés es:

#+begin_src R :exports code :results none 
  estimador_razon <- function(split, ...){
    muestra <- analysis(split)
    muestra |>
      summarise(estimate = sum(area_habitable_sup_m2) / sum(area_lote_m2),
                .groups = "drop") |>
      mutate(term = "% area del lote construida")
  }
#+end_src

Y nuestra estimación puntual es

#+begin_src R :exports both :results org 
  estimador <- muestra_casas |>
    summarise(estimate = sum(area_habitable_sup_m2) / sum(area_lote_m2))
  estimador
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 1
  estimate
     <dbl>
1    0.148
#+end_src

Es decir que en promedio, un poco más de $15\%$ del lote total es ocupado por área habitable. 
Ahora hacemos bootstrap para construir un intervalo:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-bootstrap-razon.jpeg :exports results :results output graphics file
  dist_boot <- bootstraps(casas_muestra,  2000) %>% 
    mutate(res_boot = map(splits, estimador_razon)) 
  g_1 <- ggplot(dist_boot %>% unnest(res_boot), aes(x = estimate)) +
    geom_histogram(bins = 20) + sin_lineas
  g_2 <- ggplot(dist_boot %>% unnest(res_boot), aes(sample = estimate)) +
    geom_qq() + geom_qq_line(colour = 'red') + sin_lineas
  g_1 + g_2
#+end_src

#+RESULTS:
[[file:../images/casas-bootstrap-razon.jpeg]]

En este caso la cola derecha parece tener menos dispersión que una distribución normal.
Usamos un intervalo de percentiles para obtener:

#+begin_src R :exports both :results org 
  dist_boot %>% int_pctl(res_boot) %>% 
    mutate(estimador = estimador$estimate) %>% 
    rename(media_boot = .estimate) %>% 
    mutate(bias = media_boot - estimador) %>% 
    pivot_longer(where(is_numeric)) %>% 
    mutate(value = round(value, 3))  
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 6 × 4
  term                       .method    name        value
  <chr>                      <chr>      <chr>       <dbl>
1 % area del lote construida percentile .lower      0.121
2 % area del lote construida percentile media_boot  0.142
3 % area del lote construida percentile .upper      0.159
4 % area del lote construida percentile .alpha      0.05 
5 % area del lote construida percentile estimador   0.148
6 % area del lote construida percentile bias       -0.006
Warning messages:
1: Deprecated 
2: Deprecated 
3: Deprecated 
4: Deprecated 
5: Deprecated 
6: Deprecated 
7: Deprecated 
8: Deprecated
#+end_src



Nótese que el sesgo es bajo.  De modo que en esta zona, entre $12\%$ y $16\%$ de toda
el área disponible es ocupada por área habitable: estas son casas que tienen
jardines o terrenos, garage relativamente grandes.

** Suavizadores

Podemos usar el /bootstrap/ para juzgar la variabilidad de un suavizador, que
consideramos como nuestra estadística:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-suavizador.jpeg :exports results :results output graphics file
  graf_casas <- function(data){
      ggplot(data %>% filter(calidad_gral < 7), 
          aes(x = area_habitable_sup_m2)) + 
          geom_point(aes(y = precio_m2_miles), alpha = 0.75) +
          geom_smooth(aes(y = precio_m2_miles), method = "loess", span = 0.7, 
                  se = FALSE, method.args = list(degree = 1, family = "symmetric"))     
  }
  graf_casas(muestra_casas)
#+end_src

#+RESULTS:
[[file:../images/casas-suavizador.jpeg]]


Podemos hacer bootstrap para juzgar la estabilidad del suavizador:

#+begin_src R :exports none :results none
suaviza_boot <- function(x, data){
    # remuestreo
    muestra_boot <- sample_n(data, nrow(data), replace = T)
    ajuste <- loess(precio_m2_miles ~ area_habitable_sup_m2, data = muestra_boot, 
                    degree = 1, span = 0.7, family = "symmetric")
    datos_grafica <- tibble(area_habitable_sup_m2 = seq(25, 250, 5))
    ajustados <- predict(ajuste, newdata = datos_grafica)
    datos_grafica %>% mutate(ajustados = ajustados) %>% 
        mutate(rep = x)
}
reps <- map(1:10, ~ suaviza_boot(.x, casas_muestra %>% filter(calidad_gral < 7))) %>% 
    bind_rows()
#+end_src

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-suavizador-bs.jpeg :exports results :results output graphics file
  # ojo: la rutina loess no tienen soporte para extrapolación
  graf_casas(casas_muestra) + 
    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 1, colour = "red") +
    coord_cartesian(xlim = c(50, 225)) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/casas-suavizador-bs.jpeg]]

Donde vemos que algunas cambios de pendiente del suavizador original no son muy
interpretables (por ejemplo, para áreas chicas) y alta variabilidad en general
en los extremos. Podemos hacer más iteraciones para calcular bandas de
confianza:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-suavizador-bandas.jpeg :exports results :results output graphics file
  reps <- map(1:200, ~ suaviza_boot(.x, casas_muestra %>% filter(calidad_gral < 7))) %>% 
    bind_rows()
  ## ojo: la rutina loess no tienen soporte para extrapolación
  graf_casas(casas_muestra) + 
    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 0.2, colour = "red") +
    coord_cartesian(xlim = c(50, 225)) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/casas-suavizador-bandas.jpeg]]

Donde observamos cómo tenemos incertidumbre en cuanto al nivel y forma de las
curvas en los extremos de los datos (casas grandes y chicas), lo cual es
natural. Aunque podemos resumir para hacer bandas de confianza, mostrar
remuestras de esta manera es informativo: por ejempo: vemos cómo es probable
también que para casas de emnos de 70 metros cuadrados el precio por metro
cuadrado no cambia tanto (líneas constantes)

* Conclusiones y observaciones

- El principio fundamental del /bootstrap/ es que podemos estimar
  la distribución poblacional con la distribución empírica. Por tanto para hacer
  inferencia tomamos muestras con reemplazo de la distribución empírica y
  analizamos la variación de la estadística de interés a lo largo de las
  muestras.

- El bootstrap nos da la posibilidad de crear intervalos de confianza cuando no
  contamos con fórmulas para hacerlo de manera analítica y sin supuestos
  distribucionales de la población.

- Hay muchas opciones para construir intervalos bootstrap, los que tienen
  mejores propiedades son los intervalos $\mathsf{BC}_a$, sin embargo los más
  comunes son los intervalos normales con error estándar /bootstrap/ y los
  intervalos de percentiles de la distribución /bootstrap/.

- Antes de hacer intervalos normales (o con percentiles de una $t$) vale la pena
  graficar la distribución /bootstrap/ y evaluar si el supuesto de normalidad es
  razonable.

- En cuanto al número de muestras bootstrap se recomienda al menos $1,000$ al
  hacer pruebas, y $10 , 000$ o $15 , 000$ para los resultados finales, sobre
  todo cuando se hacen intervalos de confianza de percentiles.

- La función de distribución empírica es una mala estimación en las colas de las
  distribuciones, por lo que es difícil construir intervalos de confianza
  (usando bootstrap no paramétrico) para estadísticas que dependen mucho de las
  colas.

bibliographystyle:abbrvnat
bibliography:references.bib


* Temas por ver                                                    :noexport:

- Jacknife (sesgo, reducción de sesgo)
- Bootstrap (sesgo, reducción de sesgo)
- Pruebas de permutación (pruebas estadisticas exactas)
- Validación cruzada
