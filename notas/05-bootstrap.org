#+TITLE: EST-24107: Simulación
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Remuestreo~
#+STARTUP: showall
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/05-bootstrap.pdf
:END:
#+PROPERTY: header-args:R :session bootstrap :exports both :results output org :tangle ../rscript/05-bootstrap.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc noexport 

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Otoño, 2022 | /Bootstrap/.\\
*Objetivo*: En esta sección estudiaremos los métodos de remuestreo que permiten cuantificar incertidumbre en situaciones donde nuestro estimador se construye con una sola muestra y donde no hay acceso al sistema que genera los datos. Esto contrasta con los métodos anteriores pues antes hemos estudiado bajo el supuesto de poder tener acceso al generador de números aleatorios correctos. En esta ocasión sólo tenemos una muestra y querríamos cuantificar incertidumbre en nuestros estimadores.\\
*Lectura recomendada*: El libro de [[citet:&Chihara2018]] presenta una discusión del tema bajo el esquema de análisis estadístico. El libro [[citet:&Efron1993]] es una referencia clásica para /bootstrap/. El capítulo 8 de [[citet:&Wasserman2004]] contiene una discusión condensada de /bootstrap/. El capítulo 10 de [[citet:&Efron2016]] establece el método /bootstrap/ como parte del /set/ de herramientas del estadístico moderno.
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)

  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 5)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src

* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
  - [[#contexto-histórico][Contexto histórico]]
  - [[#idea-general][Idea general]]
  - [[#ejemplo][Ejemplo]]
    - [[#ejercicio][Ejercicio:]]
  - [[#observaciones][Observaciones:]]
  - [[#la-distribución-de-muestreo][La distribución de muestreo]]
- [[#la-idea-del-bootstrap][La idea del bootstrap]]
  - [[#mundo-poblacional][Mundo poblacional]]
  - [[#mundo-bootstrap][Mundo bootstrap]]
    - [[#definición][Definición:]]
    - [[#ejemplo][Ejemplo:]]
  - [[#nota][Nota]]
    - [[#remuestreo-para-una-población][Remuestreo para una población:]]
- [[#el-principio-de-plug-in][El principio de plug-in]]
  - [[#observación][Observación]]
    - [[#ejercicio][Ejercicio:]]
  - [[#observación][Observación]]
  - [[#observación][Observación]]
  - [[#ejemplo][Ejemplo]]
- [[#propiedades-distribución-bootstrap][Propiedades distribución bootstrap]]
  - [[#ejemplo][Ejemplo]]
  - [[#variación-en-distribución-bootstrap][Variación en distribución bootstrap]]
- [[#boostrap-y-otras-estadísticas][Boostrap y otras estadísticas]]
  - [[#estimadores-de-razón][Estimadores de razón]]
  - [[#suavizadores][Suavizadores]]
- [[#jacknife-y-cuantificación-de-sesgo][Jacknife y cuantificación de sesgo]]
- [[#generalización-intervalos-de-confianza][Generalización intervalos de confianza]]
:END:


* Introducción 

El remuestreo se refiere a un conjunto de técnicas estadísticas,
computacionalmente intensivas, que ~estiman~ la /distribución de una población/
basadas en ~muestreo aleatorio con reemplazo~ de una muestra observada.

Se considera una muestra aleatoria $X_{1}, \ldots, X_{n}$ como si fuera una
población finita y se generan muestras aleatorias de la misma muestra para
estimar características poblacionales y hacer inferencia de la población
muestreada.

#+REVEAL: split
Las técnicas de remuestreo permiten calcular medidas de ajuste (en términos de
sesgo, varianza, intervalos de confianza, errores de predicción o de algunas
otras medidas) a los estimados basados en muestras.

Estas técnicas son usualmente no paramétricas, y varias son tan antiguas como la
estadística misma. Por ejemplo, las técnicas de permutación son de Fisher (1935)
y Pitmann (1937); la validación cruzadas fue propuesta por Kurtz en 1948, y el
/Jackknife/ fue propuesto por Maurice Quenouille en 1949 aunque fue John Tukey en
1958 quién le dio el nombre a la técnica.

** Contexto histórico

Bradley Efron introdujo el ~bootstrap~ en 1979.  El término ‘bootstrapping’ se
refiere al concepto de “pulling oneself up by one’s bootstraps”, frase que
aparentemente se usó por primera vez en:
- Raspe, R. E. (1786). /Gulliver Revived: Or the Singular Travels, Campaigns,
  Voyages, and Adventures of Baron Munikhouson, Commonly Called Munchausen/.

** Idea general

El objetivo del remuestreo es estimar alguna característica poblacional,
representada por $\theta$ (tal como media, mediana, desviación estándar,
coeficientes de regresión, matriz de covarianza, etc.) ~basada sólo en los datos observados~.

También interesan las propiedades de la ~distribución de estimador~, sin hacer supuestos
restrictivos sobre la forma de la distribución de los datos originales.

Para una muestra aleatoria $X_1, \ldots , X_n$ , la ~distribución de remuestreo~ es la distribución
empírica $\hat{\mathbb{P}}_n$, que asigna probabilidad $1/n$ a cada una de las observaciones de la muestra.

\newpage

** Ejemplo

Consideremos una muestra de 6 parejas. La variable de interés es la diferencia
del ingreso de los miembros de cada pareja (en miles de pesos al mes).

|-----+-------------+-------------+-------------------------------|
| $i$ | $P_i^{(1)}$ | $P_i^{(2)}$ | $d_i = P_i^{(1)} - P_i^{(2)}$ |
|-----+-------------+-------------+-------------------------------|
|   1 |          24 |          18 |                             6 |
|   2 |          14 |          17 |                            -3 |
|   3 |          40 |          35 |                             5 |
|   4 |          44 |          41 |                             3 |
|   5 |          35 |          37 |                            -2 |
|   6 |          45 |          45 |                             0 |
|-----+-------------+-------------+-------------------------------|

#+REVEAL: split
Definamos $\theta$ como el promedio de las diferencias de ingreso poblacional. Podemos estimar $\theta$ con
\begin{align}
\hat \theta_n= \frac{6 - 3 + 5 + 3 - 2+ 0}{6} = 1.5\,.
\end{align}
¿Cómo calculamos la variabilidad de nuestro estimador? Es decir, ¿cómo
calculamos la variabilidad de $\hat \theta_n$?

*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:
Escribe la fórmula del error estándar bajo los siguientes supuestos:
1. La diferencia tiene una distribución $d_i \sim \mathsf{N}(\theta, \sigma^2)$.
2. La varianza $\sigma^2$ es conocida.

** ~Observaciones~:
- Suponer que la diferencia de ingresos $d_i$ se comporta como una variable normal puede
  no estar /tan/ errado. Pues con un número suficiente de muestras podríamos
  suponer que el resultado del $\mathsf{TLC}$ se cumple. Entonces, ¿qué hacemos
  si no conocemos la distribución de las observaciones?

- Si no conocemos $\sigma^2$  lo podemos estimar con la muestra. Por ejemplo, podemos
  utilizar intervalos de confianza derivados de una distribución $t_{n-1}$.

- Si nos interesa otro parámetro de la población podemos construir estimadores
  diferentes. Por ejemplo, nos podría interesar la ~mediana~ de una población
  $q_{0.5} = \mathbb{P}^{-1}(1/2)$. Para este caso, podemos estimar dicho parámetro
  por medio de
  \begin{align}
  \hat q_{0.5} = \begin{cases}
    X_{(\frac{n+1}{2})} & \text{ si } n \text{ es impar }\\
    \frac{X_{(n/2)} + X_{(n/2 + 1)}}{2} & \text{ si } n \text{ es par }
  \end{cases} \,.
  \end{align}


#+REVEAL: split
  En [[fig-medianas]] la estimación de la mediana en distintos grupos acompañados de su estimación de incertidumbre. 
#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-medianas-grupos.jpeg :exports results :results output graphics file :tangle no :eval never
    set.seed(8)
    ## Generamos nuestros datos ficticios - poblacion 
    pob_tab <- tibble(id = 1:2000,
                      x = rgamma(2000, 4, 1), 
                      grupo = sample(c("a","b", "c"),
                                     2000, prob = c(4,2,1),
                                     replace = T))
    ## Generamos una muestras - observaciones 
    muestra_tab <- pob_tab |> 
      sample_n(125)
    g_1 <- ggplot(muestra_tab, aes(x = grupo, y = x)) + 
      geom_boxplot(outlier.alpha = 0) +
      geom_jitter(alpha = 0.3) +  sin_lineas + 
      labs(subtitle = "Muestra \n") + ylim(c(0,14))
    ## Hacemos bootstrap 
    fun_boot <- function(datos){
        datos |> group_by(grupo) |>
          sample_n(n(), replace = TRUE)
    }
    reps_boot <- map_df(1:2000, function(i){
      muestra_tab %>% 
        fun_boot %>%
        group_by(grupo) %>%
        summarise(mediana = median(x), .groups = "drop")}, 
      .id = 'rep') 
    resumen_boot <- reps_boot |> group_by(grupo) |> 
        summarise(ymin = quantile(mediana, 0.025), 
                  ymax = quantile(mediana, 0.975), .groups = "drop") |> 
        left_join(muestra_tab |> 
                    group_by(grupo) |> 
                    summarise(mediana = median(x)), .groups = "drop")
    g_2 <- ggplot(resumen_boot, aes(x = grupo, y = mediana, ymin = ymin, 
                                    ymax = ymax)) +
        geom_linerange() + sin_lineas +
        geom_point(colour = "red", size = 2) +  ylim(c(0,14)) +
        labs(subtitle = "Intervalos de 95% \n para la mediana")
    g_1 + g_2
#+end_src
#+name: fig-medianas
#+caption:Estimación de mediana (panel izquierdo) con intervalos de incertidumbre (panel derecho). 
#+RESULTS:
[[file:../images/bootstrap-medianas-grupos.jpeg]]

** La distribución de muestreo

Hasta ahora lo que hemos hecho es estimar $\hat{\pi}_N^{\mathsf{MC}}(f) \approx
\pi(f) = \int f(x) \, \pi(x) \, \text{d}x$ por medio de muestras de la densidad
$\pi(\cdot)$. Es decir, por medio de
\begin{align}
X_{1}, \ldots, X_{N} \overset{\mathsf{iid}}{\sim} \pi\,.
\end{align}

#+REVEAL: split
Hemos considerado la noción ~frecuentista~ de medir nuestra incertidumbre en nuestro estimador por medio del *error estándar* de nuestro estimador. Donde éste último está definido como
\begin{align}
\mathsf{ee}\left(\hat{\pi}_N^{\mathsf{MC}}(f) \right) = \left( \mathbb{V}(\hat{\pi}_N^{\mathsf{MC}}(f) ) \right)^{1/2}\,,
\end{align}
y la varianza es con respecto a la variabilidad que /nace/ por haber observado distintas muestras.

#+REVEAL: split
Es decir, estamos considerando la situación en que podemos replicar el proceso
de muestreo tantas veces como queramos (o recursos computacionales tengamos).
Denotemos por $B$ el número de réplicas que podemos realizar y denotemos por
\begin{align}
X^{(b)}_{1}, \ldots, X^{(b)}_{N} \overset{\mathsf{iid}}{\sim} \pi\,, \qquad b = 1, \ldots, B\,,
\end{align}
las réplicas que generamos.

#+REVEAL: split
Notemos que es a través de este proceso de crear réplicas que podemos construir
una distribución para $\hat{\pi}_N^{\mathsf{MC}}(f)$ y notemos, además, que
nuestro estimador es el resultado de aplicar una función a la muestra dada
\begin{align}
\hat{\pi}_N^{\mathsf{MC}, (b)}(f) = t(X^{(b)}_{1}, \ldots, X^{(b)}_{N})\,, \qquad b = 1, \ldots, B\,.
\end{align}

La distribución resultante de nuestro estimador
$\hat{\pi}_N^{\mathsf{MC}}(f)$ derivada de haber observado un conjunto de datos
distinto es lo que en sus cursos de estadística le llamamos ~distribución de
muestreo~ del estimador.

#+REVEAL: split
Nota que en esta situación asumimos que podemos generar tantas muestras como
queramos de la distribución de interés $\pi$. En esta sección del curso
estudiaremos un mecanismo para cuando no podemos hacer eso (generar muestras de
una población) y sólo tenemos acceso a una muestra---que asumimos aleatoria---de
la población que nos interesa.

* La idea del /bootstrap/

Como explicamos, el problema que tenemos ahora es que normalmente sólo tenemos
una muestra, así que no es posible calcular las distribuciones de muestreo como
hicimos arriba y evaluar qué tan preciso es nuestro estimador. Sin embargo,
podemos hacer lo siguiente:

Supongamos que tenemos una muestra $X_1,X_2,\dots, X_n$ independientes de alguna
población desconocida y un estimador $T_n=t(X_1,\dots, X_n)$

** Mundo poblacional

1. Si tuviéramos la distribución poblacional, simulamos muestras iid para
   aproximar la distribución de muestreo de nuestro estimador, y así entender su
   variabilidad.
2. Pero *no* tenemos la distribución poblacional.
3. *Sin embargo, podemos estimar la distribución poblacional con nuestros valores muestrales*.

** Mundo /bootstrap/

4. Si usamos la estimación del inciso 3, entonces usando el inciso 1 podríamos
   tomar muestras de nuestros datos muestrales, como si fueran de la población,
   y usando el mismo tamaño de muestra. El muestreo lo hacemos con reemplazo de
   manera que produzcamos muestras independientes de la misma "población
   estimada", que es la muestra.
5. Evaluamos nuestra estadística en cada una de estas remuestras.
6. A la distribución resultante le llamamos *distribución /bootstrap/* o
   *distribución de remuestreo* del estimador.
7. Usamos la distribución /bootstrap/ de la muestra para estimar la variabilidad
   en nuestra estimación con *la muestra original*.

#+REVEAL: split
El esquema de esta estrategia lo podemos representar con la figura siguiente
#+DOWNLOADED: screenshot @ 2022-09-20 08:58:18
#+attr_html: :width 700 :align center
#+attr_latex: :width .65 \linewidth
[[file:images/20220920-085818_screenshot.png]]


#+REVEAL: split
Veamos que sucede para un ejemplo concreto, donde  nos interesa estimar
la media de los precios de venta de una población de casas. Tenemos nuestra muestra:

#+begin_src R :exports both :results none
  set.seed(2112)
  poblacion_casas <- read_csv("data/casas.csv")
  muestra <- sample_n(poblacion_casas, 200, replace = TRUE) |>
    select(id, nombre_zona, area_habitable_sup_m2, precio_miles)
#+end_src

#+begin_src R :exports results :results org 
  head(muestra)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 6 × 4
     id nombre_zona area_habitable_sup_m2 precio_miles
  <dbl> <chr>                       <dbl>        <dbl>
1   502 Somerst                     164.          227.
2    79 Sawyer                      164.          136.
3   440 Edwards                     111.          110 
4   524 Edwards                     434.          185.
5  1442 CollgCr                      78.8         149.
6   769 CollgCr                     171.          217.
#+end_src

#+begin_src R :exports results :results org 
  sprintf("Hay %0.0f casas en total, tomamos muestra de %0.0f",
        nrow(poblacion_casas), nrow(muestra))
#+end_src

#+RESULTS:
#+begin_src org
[1] "Hay 1144 casas en total, tomamos muestra de 200"
#+end_src

#+REVEAL: split
Esta muestra nos da nuestro estimador de la distribución poblacional.

#+begin_src R :exports both :results org 
  mean(muestra$precio_miles)  
#+end_src

#+RESULTS:
#+begin_src org
[1] 179.96
#+end_src

Por ejemplo, podemos fijarnos en un gráfico con histogramas:


#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-qqplot.jpeg :exports results :results output graphics file :tangle no :eval never
  bind_rows(muestra |> mutate(tipo = "muestra"),
      poblacion_casas |> mutate(tipo = "población")) |>  
  ggplot(aes(sample = precio_miles, colour = tipo, group = tipo)) + 
    geom_qq(distribution = stats::qunif, alpha = 0.4, size = 1) +
    facet_wrap(~ tipo) + sin_lineas + sin_leyenda
#+end_src

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-histogramas.jpeg :exports results :results output graphics file
  bind_rows(muestra |> mutate(tipo = "muestra"),
      poblacion_casas |> mutate(tipo = "población")) |>
  ggplot(aes(x = precio_miles, group = tipo)) + 
      geom_histogram(aes(y=..density..), binwidth = 50) + 
    facet_wrap(~ tipo) + sin_lineas + sin_leyenda
#+end_src

#+RESULTS:
[[file:../images/casas-histogramas.jpeg]]

Y vemos que la aproximación es razonable en las partes centrales de la 
distribución. 

#+REVEAL: split
Ahora supongamos que nos interesa cuantificar la precisión de nuestra
estimación de la media poblacional de precios de casas, y usaremos la media
muestral para hacer esto. Para nuestra muestra, nuestra estimación puntual es:

#+begin_src R :exports both :results org 
  media <- mean(muestra$precio_miles)
  media
#+end_src

#+RESULTS:
#+begin_src org
[1] 179.96
#+end_src


Y recordamos que para aproximar la distribución de muestreo podíamos muestrear
repetidamente la población y calcular el valor del estimador en cada una de
estas muestras. Aquí no tenemos la población, *pero tenemos una estimación de la
población*: la muestra obtenida.

#+REVEAL: split
Así que para evaluar la variabilidad de nuestro estimador, entramos en el mundo
boostrap, y consideramos que la población es nuestra muestra.

Podemos entonces extraer un número grande de muestras con reemplazo de tamaño
200 *de la muestra*: el muestreo debe ser análogo al que se tomó para nuestra
muestra original. Evaluamos nuestra estadística (en este caso la media) en cada
una de estas remuestras:

#+REVEAL: split
#+begin_src R :exports code :results none
  ## paso 1: definimos un mecanismo de remuestreo
  genera_remuestras <- function(data, n = 200){
    data |>
      sample_n(200, replace = TRUE)
  }
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  ## paso 2: definimos la estimacion del parametro
  calcula_estimador <- function(data){
    data |>
      summarise(media_precio = mean(precio_miles), .groups = "drop")
  }
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results org 
  ## paso 3: aplicamos el proceso de remuestreo y estimacion
  media_muestras <- map_dbl(1:1000, function(id){
    genera_remuestras(muestra) |>
      calcula_estimador() |>
      pull(media_precio)})
  media_muestras[1:10]
#+end_src

#+RESULTS:
#+begin_src org
 [1] 176.38 175.96 175.91 176.35 177.77 186.78 179.23 181.62 175.07 177.13
#+end_src

#+REVEAL: split
Y nuestra estimación de la distribución de muestreo para la media es entonces:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-bootstrap.jpeg :exports results :results output graphics file
  bootstrap <- tibble(media = media_muestras)
  g_cuantiles <- ggplot(bootstrap, aes(sample = media)) +
    geom_qq(distribution = stats::qunif) +
    ggtitle("QQ-plots de la distribución \nde la media") +
    sin_lineas
  g_histograma <- ggplot(bootstrap, aes(x = media)) +
    geom_histogram(binwidth = 2) + sin_lineas +
    ggtitle("Histograma de la distribución \nde la media")
  g_cuantiles + g_histograma
#+end_src

#+RESULTS:
[[file:../images/casas-bootstrap.jpeg]]

#+REVEAL: split
A esta le llamamos la distribución de remuestreo de la media, que definimos más
abajo. Ahora podemos calcular un intervalo de confianza del $90\%$ simplemente
calculando los cuantiles de esta distribución (no son los cuantiles de la
muestra original!):

#+begin_src R :exports both :results org 
  limites_ic <- quantile(media_muestras, c(0.05,  0.95)) |> round(4)
  limites_ic
#+end_src

#+RESULTS:
#+begin_src org
    5%    95% 
174.81 194.06
#+end_src

#+REVEAL: split
Otra cosa que podríamos hacer para describir la dispersión de nuestro estimador
es calcular el error estándar de remuestreo, que estima el error estándar de la
distribución de muestreo:

#+begin_src R :exports both :results org
  ee_boot <- sd(media_muestras)
  round(ee_boot, 2)
#+end_src

#+RESULTS:
#+begin_src org
[1] 5.71
#+end_src

*** ~Definición~:
Sea $X_1,X_2,\ldots,X_n$ una muestra independiente y idénticamente distribuida
($\mathsf{iid}$), y $T_n=t(X_1, X_2, \ldots, X_n)$ una estadística. Supongamos
que los valores que obervamos son $x_1, x_2,\ldots, x_n$.

#+REVEAL: split
La *distribución de remuestreo* de $T_n$ es la distribución de $T^*=t(X_1^*, X_2^*,
\dots X_n^*)$, donde cada $X_i^*$ se obtiene tomando al azar uno de los valores
de $x_1,x_2,\ldots, x_n$.

Otra manera de decir esto es que la remuestra $X_1^*, X_2^*, \ldots, X_n^*$ es una muestra
con reemplazo de los valores observados $x_1, x_2, \ldots, x_n$

*** ~Ejemplo~:
Si observamos la muestra

#+begin_src R :exports both :results org 
  muestra <- sample(1:20, 5)
  muestra
#+end_src

#+RESULTS:
#+begin_src org
[1]  2  9 10  1 18
#+end_src

Una remuestra se obtiene:

#+begin_src R :exports both :results org 
  sample(muestra, size = 5, replace = TRUE)
#+end_src

#+RESULTS:
#+begin_src org
[1]  9 10  2 10 10
#+end_src

Nótese que algunos valores de la muestra original pueden aparecer varias veces, y otros no aparecen del todo.

** Nota
La muestra original es una aproximación de la población
de donde fue extraída. Así que remuestrear la muestra aproxima lo que pasaría si
tomáramos muestras de la población. La *distribución de remuestreo* de una
estadística, que se construye tomando muchas remuestras, aproxima la
distribución de muestreo de la estadística.

Y el proceso que hacemos es:

*** ~Remuestreo para una población~:
:PROPERTIES:
:reveal_background: #00468b
:END:

Dada una muestra de tamaño $n$ de una población, 

1. Obtenemos una remuestra de tamaño $n$ con reemplazo de la muestra original
2. Repetimos este remuestreo muchas veces (por ejemplo $10,000$).
3. Construímos la distribución /bootstrap/, y examinamos sus características
   (dónde está centrada, dispersión y forma).

* El principio de /plug-in/

La idea básica detrás del /bootstrap/ es el principio de /plug-in/ para estimar
parámetros poblacionales: si queremos estimar una cantidad poblacional,
calculamos esa cantidad poblacional con la muestra obtenida. Es un principio
común en estadística.

#+REVEAL: split
Por ejemplo, si queremos estimar la media o desviación estándar poblacional,
usamos la media muestral o la desviación estándar muestral. Si queremos estimar
un cuantil de la población usamos el cuantil correspondiente de la muestra, y
así sucesivamente.

#+REVEAL: split
En todos estos casos, lo que estamos haciendo es:

- Tenemos una fórmula para la cantidad poblacional de interés en términos de la
  distribución poblacional.
- Tenemos una muestra, que usamos para estimar la cantidad poblacional. La
  distribución que da una muestra se llama distribución *empírica*.
- Contruimos nuestro estimador ``enchufando'' la distribución empírica de la
  muestra en la fórmula del estimador.

#+REVEAL: split
En el /bootstrap/ aplicamos este principio simple a la *distribución de 
muestreo*:

- *Si tenemos la población*, podemos *calcular* la distribución de muestreo de
  nuestro estimador tomando muchas muestras de la *población*.
- Estimamos la *poblacion* con la *muestra* y enchufamos en la frase anterior:
- Podemos *estimar* la distribucion de muestreo de nuestro estimador tomando
  muchas muestras de la *muestra* (/bootstrap/).

#+REVEAL: split
Nótese que el proceso de muestreo en el último paso *debe ser el mismo* que
se usó para tomar la muestra original. Estas dos imágenes simuladas con base en 
un ejemplo de citep:Chihara2018 muestran lo que acabamos de describir:

#+REVEAL: split
#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/mundo-poblacional.jpeg :exports results :results output graphics file :tangle no 
  library(LaplacesDemon)
  library(patchwork)
  ## En este ejemplo la población es una mezcla de normales
  pob_plot <- ggplot(data_frame(x = -15:20), aes(x)) +
    stat_function(fun = dnormm, args = list(p = c(0.3, 0.7), mu = c(-2, 8),
                                            sigma = c(3.5, 3)), alpha = 0.8) +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    scale_colour_manual(values = c('mu' = 'red'), name = '', 
                        labels = expression(mu)) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", subtitle = expression("Población "~F), color = "") +
    theme_classic()

  samples <- data_frame(sample = 1:3) |>
    mutate(sims = rerun(3, rnormm(30, p = c(0.3, 0.7), mu = c(-2, 8), 
                                  sigma = c(3.5, 3))), 
           x_bar = map_dbl(sims, mean))

  muestras_plot <- samples |>
    unnest(cols = c(sims)) |> 
    ggplot(aes(x = sims)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_segment(aes(x = x_bar, xend = x_bar, y = 0, yend = 0.8), 
                 color = "blue") +
    xlim(-15, 20) +
    facet_wrap(~ sample) +
    scale_y_continuous(breaks = NULL) +
    geom_text(aes(x = x_bar, y = 0.95, label = "bar(x)"), parse = TRUE, 
              color = "blue", alpha = 0.2, hjust = 1) +
    labs(x = "", subtitle = "Muestras") +
    theme_classic() +
    theme(strip.background = element_blank(), strip.text.x = element_blank())

  samples_dist <- tibble(sample = 1:10000) |>
    mutate(sims = rerun(10000, rnormm(100, p = c(0.3, 0.7), mu = c(-2, 8), 
                                      sigma = c(3.5, 3))), 
           mu_hat = map_dbl(sims, mean))
  dist_muestral_plot <- ggplot(samples_dist, aes(x = mu_hat)) +
    geom_density(adjust = 2) +
    scale_y_continuous(breaks = NULL) +
    labs(x = "", y = "",
         subtitle = expression("Distribución muestral de "~hat(mu)==bar(X))) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    theme_classic()

  (pob_plot | plot_spacer()) / (muestras_plot | dist_muestral_plot) 
#+end_src

#+RESULTS:
[[file:../images/mundo-poblacional.jpeg]]

#+REVEAL: split
 #+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/mundo-bootstrap.jpeg :exports results :results output graphics file :tangle no
  dist_empirica <- tibble(id = 1:30, obs = samples$sims[[1]])

  dist_empirica_plot <- ggplot(dist_empirica, aes(x = obs)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    geom_vline(aes(xintercept = samples$x_bar[1], color = "x_bar"), 
               alpha = 0.8, linetype = "dashed") +
    xlim(-15, 20) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    labs(x = "", subtitle = expression("Distribución empírica"~hat(F))) +
    scale_colour_manual(values = c('mu' = 'red', 'x_bar' = 'blue'), name = '', 
                        labels = c(expression(mu), expression(bar(x)))) +
    scale_y_continuous(breaks = NULL) +
    theme_classic()

  samples_boot <- tibble(sample_boot = 1:3) |> 
    mutate(
      sims_boot = rerun(3, sample(dist_empirica$obs, replace = TRUE)), 
      x_bar_boot = map_dbl(sims_boot, mean)
    )

  muestras_boot_plot <- samples_boot |>
    unnest(cols = c(sims_boot)) |> 
    ggplot(aes(x = sims_boot)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(xintercept = samples$x_bar[1]), color = "blue",
               linetype = "dashed", alpha = 0.8) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_segment(aes(x = x_bar_boot, xend = x_bar_boot, y = 0, yend = 0.8), 
                 color = "black") +
    xlim(-15, 20) +
    facet_wrap(~ sample_boot) +
    geom_text(aes(x = x_bar_boot, y = 0.95, label = "bar(x)^'*'"), 
              parse = TRUE, color = "black", alpha = 0.3, hjust = 1) +
    labs(x = "", subtitle = "Muestras bootstrap") +
    scale_y_continuous(breaks = NULL) +
    theme_classic() +
    theme(strip.background = element_blank(), strip.text.x = element_blank())

  boot_dist <- data_frame(sample = 1:10000) |>
    mutate(
      sims_boot = rerun(10000, sample(dist_empirica$obs, replace = TRUE)), 
      mu_hat_star = map_dbl(sims_boot, mean))
  boot_muestral_plot <- ggplot(boot_dist, aes(x = mu_hat_star)) +
    geom_histogram(alpha = 0.5, fill = "darkgray", bins = 30) +
    labs(x = "", 
         subtitle = expression("Distribución bootstrap de "~hat(mu)^'*'==bar(X))) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_vline(aes(xintercept = samples$x_bar[1]), color = "blue", 
               linetype = "dashed", alpha = 0.8) +
    scale_y_continuous(breaks = NULL) +
    theme_classic()

  (dist_empirica_plot | plot_spacer()) / (muestras_boot_plot | boot_muestral_plot) 
#+end_src

#+RESULTS:
[[file:../images/mundo-bootstrap.jpeg]]

** Observación
Veremos ejemplos más complejos, pero nótese que si la muestra original son
observaciones independientes obtenidas de la distribución poblacional, entonces
logramos esto en las remuestras tomando aleatoriamente observaciones con
reemplazo de la muestra. Igualmente, las remuestras deben ser del mismo tamaño
que la muestra original.

*** ~Ejercicio~:
:PROPERTIES:
:reveal_background: #00468b
:END:

- ¿Porqué no funcionaría tomar muestras sin reemplazo? Piensa si hay
  independencia entre las observaciones de la remuestra, y cómo serían las
  remuestras sin reemplazo.
- ¿Por qué no se puede hacer bootstrap si no conocemos cómo se obtuvo la muestra
  original?


** Observación
Estos argumentos se pueden escribir con fórmulas usando por ejemplo la función
de distribución acumulada $\mathbb{P}$ de la población y su estimador, que es la función
empírica $\hat{\mathbb{P}}_n$, como en citep:Efron1993.  Si $\theta = t(\mathbb{P})$ es una cantidad
poblacional que queremos estimar, su estimador /plug-in/ es $\hat{\theta} =
t(\hat{\mathbb{P}}_n)$.

** Observación
La distribución empírica $\hat{\mathbb{P}}_n$ es un estimador /razonable/ de la
distribución poblacional $\mathbb{P}$ pues por el teorema de Glivenko-Cantelli
(citep:Wasserman2004, o [[https://en.wikipedia.org/wiki/Glivenko-Cantelli_theorem][aquí]]), $\hat{\mathbb{P}}_n$ converge a $\mathbb{P}$ cuando el tamaño de
muestra $n\to\infty$, lo cual es intuitivamente claro.

** Ejemplo 
En el siguiente ejemplo (tomadores de té), podemos estimar la proporción de
tomadores de té que prefiere el té negro usando nuestra muestra:

#+begin_src R :exports both :results none
  te <- read_csv("data/tea.csv") |>
    rowid_to_column() |>
    select(rowid, Tea, sugar)
#+end_src

#+begin_src R :exports both :results org 
  te |>
    mutate(negro = ifelse(Tea == "black", 1, 0)) |>
    summarise(prop_negro = mean(negro), n = length(negro), .groups = "drop")
#+end_src


#+RESULTS:
#+begin_src org
# A tibble: 1 × 2
  prop_negro     n
       <dbl> <int>
1      0.247   300
#+end_src

#+REVEAL: split
¿Cómo evaluamos la precisión de este estimador? Supondremos que el estudio se
hizo tomando una muestra aleatoria simple de tamaño 300 de la población de tomadores de té que
nos interesa. Podemos entonces usar el boostrap:

#+REVEAL: split
#+begin_src R :exports code :results none 
  ## paso 1: define el estimador
  calc_estimador <- function(datos){
    prop_negro <- datos |>
      mutate(negro = ifelse(Tea == "black", 1, 0)) |>
      summarise(prop_negro = mean(negro), n = length(negro), .groups = "drop") |>
      pull(prop_negro)
    prop_negro
  }  
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none 
  ## paso 2: define el proceso de remuestreo
  muestra_boot <- function(datos){
    ## tomar muestra con reemplazo del mismo tamaño
    sample_n(datos, size = nrow(datos), replace = TRUE)
  }  
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none 
  ## paso 3: define el proceso de bootstrap
  aplica_bootstrap <- function(id){
    muestra_boot(datos = te) |>
      calc_estimador()
  }
#+end_src


#+REVEAL: split
#+begin_src R :exports code :results none 
  # paso 4: aplica el proceso de bootstrap
  prop_negro_tbl <- map_dbl(1:2000, aplica_bootstrap ) |>
    as_tibble() |>
    rename( prop_negro = value)
#+end_src

#+REVEAL: split
#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-tea-mean.jpeg :exports results :results output graphics file
  ## paso 5: examina la distribución bootstrap
  prop_negro_tbl |>
    ggplot(aes(x = prop_negro)) +
    geom_histogram(bins = 15) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/bootstrap-tea-mean.jpeg]]

#+REVEAL: split
Y podemos evaluar varios aspectos, por ejemplo dónde está centrada y 
qué tan dispersa es la distribución /bootstrap/:

#+begin_src R :exports both :results org 
  prop_negro_tbl |>
    summarise(
      cuantil_75 = quantile(prop_negro, 0.75), 
      media = mean(prop_negro),
      cuantil_25 = quantile(prop_negro, 0.25),
      sesgo = mean(prop_negro) - 0.2499,
      ee = sd(prop_negro),
      .groups = "drop") |>
    mutate(across(where(is.numeric), round, 4))
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 5
  cuantil_75 media cuantil_25   sesgo     ee
       <dbl> <dbl>      <dbl>   <dbl>  <dbl>
1      0.263 0.246       0.23 -0.0034 0.0242
#+end_src

* Propiedades distribución /bootstrap/

Uasremos la distribución /bootstrap/ principalmente para evaluar la variabilidad
de nuestros estimadores (y también otros aspectos como sesgo) estimando
la dispersión de la distribución de muestreo. Sin embargo, es importante notar
que *no* la usamos, por ejemplo, para saber dónde está centrada la distribución 
de muestreo, o para ``mejorar'' la estimación remuestreando.

** Ejemplo

En nuestro ejemplo, podemos ver varias muestras (por ejemplo 20) de tamaño 200.
Podemos calcular las distribuciones de remuestreo para cada muestra bootstrap y
compararlas con la distribución de muestreo real. El procedimiento es como sigue.

#+REVEAL: split
#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/distribucion-boostrap.jpeg :exports results :results output graphics file :tangle no :eval never
  set.seed(911)
  muestras <- map(1:20, function(x) {
    muestra <- sample_n(poblacion_casas, 200, replace = T) |>
      mutate(rep = x, tipo = "muestras")}) |> bind_rows()
  dat_pob <- poblacion_casas |> mutate(tipo = "población", rep = 1)
  datos_sim <- bind_rows(dat_pob, muestras)

  ggplot(datos_sim, aes(sample = precio_miles, group = interaction(tipo, rep))) + 
    geom_qq(distribution = stats::qunif, alpha = 0.7, size = 0.5, geom = "line") + 
    geom_qq(data = dat_pob, aes(sample = precio_miles), colour = "red", size = 1,
            distribution = stats::qunif, geom="point") +
    scale_y_log10(breaks = c(50, 100, 200, 400, 800)) + sin_lineas
#+end_src


#+begin_src R :exports code :results none 
  ## paso 1: define el estimador
  calc_estimador <- function(datos){
    media_precio <- datos |>
      summarise(media = mean(precio_miles), .groups = "drop") |>
      pull(media)
    media_precio
  }
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none 
  ## paso 2: define el proceso de remuestreo
  muestra_boot <- function(datos, n = NULL){
    ## tomar muestra con reemplazo del mismo tamaño
    if(is.null(n)){
        m <- sample_n(datos, size = nrow(datos), replace = TRUE)}
    else {
        m <- sample_n(datos, size = n, replace = TRUE)
      }
    m
  }
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none 
  ## paso 3: define el proceso de bootstrap
  aplica_bootstrap <- function(data, n = NULL){
    data |>
      muestra_boot(n) |>
      calc_estimador()
  }
#+end_src


#+REVEAL: split
#+begin_src R :exports code :results none :tangle no :eval never
  ## paso 4: realiza el remuestreo y calcula estimadores
  dist_boot <- datos_sim |>
    filter(tipo == "muestras") |>
    select(precio_miles, rep) |> 
    group_by(rep) |> nest() |> 
    mutate(precio_miles =  map(data, function(data){
      tibble(precio_miles = rerun(1000, aplica_bootstrap(data)))
    })) |>
    select(rep, precio_miles) |>
    unnest(precio_miles) |>
    mutate(precio_miles = unlist(precio_miles))

  write_rds(dist_boot, "cache/sims_boot_precios.rds")
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none :tangle no :eval never
  ## extra: comparamos contra distribucion de muestreo
  dist_muestreo <- datos_sim |>
    filter(tipo == "población") |>
    group_by(rep) |> nest() |>
    mutate(precio_miles =  map(data, function(data){
      tibble(precio_miles = rerun(1000, aplica_bootstrap(data, n = 200)))
    })) |>
    select(rep, precio_miles) |>
    unnest(precio_miles) |>
    mutate(precio_miles = unlist(precio_miles))
  write_rds(dist_muestreo, "cache/sims_muestreo_precios.rds")
#+end_src

#+REVEAL: split
#+HEADER: :width 1200 :height 900 :R-dev-args bg="transparent"
#+begin_src R :file images/precios-distribucion-bootstrap.jpeg :exports results :results output graphics file :eval never
  dist_muestreo <- read_rds("cache/sims_muestreo_precios.rds")
  dist_boot <- read_rds("cache/sims_boot_precios.rds")
  mean_boot <- dist_boot |> summarise(media = mean(precio_miles)) |> filter(rep <= 16)
  dist_boot |>
    ungroup() |>
    filter(rep <= 16) |>
    ggplot(aes(x = precio_miles)) +
    geom_histogram(data = dist_muestreo |> ungroup() |> select(precio_miles),
                   fill = "lightblue", alpha = .6,
                   position = "identity", bins = 20) +
    geom_histogram(alpha = .6, fill = "salmon", bins = 20) +
    geom_vline(data = mean_boot, aes(xintercept = media), color = 'black', lty = 2) +
    geom_vline(data = dist_muestreo |>
                 ungroup() |>
                 select(precio_miles) |>
                 summarise(media = mean(precio_miles)),
               aes(xintercept = media), color = 'black') +
    facet_wrap(~rep) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/precios-distribucion-bootstrap.jpeg]]


#+HEADER: :width 1200 :height 700 :R-dev-args bg="transparent"
#+begin_src R :file images/distribucion-bootstrap.jpeg :exports results :results output graphics file :tangle no :eval never
  ggplot(dist_boot, aes(sample = precio_miles, group = interaction(rep))) + 
    geom_qq(distribution = stats::qunif, size = 0.1, alpha = 0.1) + 
    geom_qq(data = dist_muestreo, aes(sample = precio_miles), colour = "red",
            distribution = stats::qunif, alpha = 0.1) +
    ylim(c(125, 230)) + sin_lineas + 
    labs(subtitle = "Estimaciones de distribución \n de muestreo (media)")
#+end_src

#+REVEAL: split
Obsérvese que:

- En algunos casos la aproximación es mejor que en otros (a veces la muestra
  tiene valores ligeramente más altos o más bajos).
- La dispersión de cada una de estas distribuciones /bootstrap/ es similar a la de
  la verdadera distribución de muestreo (en rojo), pero puede está desplazada
  dependiendo de la muestra original que utilizamos.
- Adicionalmente, los valores centrales de la distribución de /bootstrap/ tiende
  cubrir el verdadero valor que buscamos estimar, que es:
  #+begin_src R :exports both :results org 
    poblacion_casas |>
      summarise(media = mean(precio_miles), .groups = "drop")  
  #+end_src

  #+RESULTS:
  #+begin_src org
  # A tibble: 1 × 1
    media
    <dbl>
  1  183.
  #+end_src

** Variación en distribución /bootstrap/

En el proceso de estimación bootstrap hay dos fuentes de variación pues:

- La muestra original se selecciona con aleatoriedad de una población.
- Las muestras /bootstrap/ se seleccionan con aleatoriedad de la muestra
  original. Esto es, la estimación bootstrap ideal es un resultado asintótico
  $B=\infty$, en esta caso $\hat{\textsf{ee}}_B$ iguala la estimación /plug-in/
  $\mathsf{ee}_{\mathbb{P}_n}$.

#+REVEAL: split
En el proceso de *bootstrap* podemos controlar la variación del segundo aspecto,
conocida como *implementación de muestreo Monte Carlo*, y la variación Monte Carlo
decrece conforme incrementamos el número de muestras.

#+REVEAL: split
Podemos eliminar la variación Monte Carlo si seleccionamos todas las posibles
muestras con reemplazo de tamaño $n$, hay ${2n-1}\choose{n}$ posibles muestras y
si seleccionamos todas obtenemos $\hat{\textsf{ee}}_\infty$ (bootstrap ideal),
sin embargo, en la mayor parte de los problemas no es factible proceder así.

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/bootstrap-variacion.jpeg  :exports results :results output graphics file :eval never :tangle no
  set.seed(8098)
  pob_plot <- ggplot(data_frame(x = -15:20), aes(x)) +
    stat_function(fun = dnormm, args = list(p = c(0.3, 0.7), mu = c(-2, 8), 
                                            sigma = c(3.5, 3)), alpha = 0.8) +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5) +
    scale_colour_manual(values = c('mu' = 'red'), name = '', 
                        labels = expression(mu)) +
    labs(x = "", y = "", subtitle = "Población", color = "") +
    theme(axis.text.y = element_blank())

  samples <- data_frame(sample = 1:6) %>% 
    mutate(
      sims = rerun(6, rnormm(50, p = c(0.3, 0.7), mu = c(-2, 8), 
                             sigma = c(3.5, 3))), 
      x_bar = map_dbl(sims, mean))

  means_boot <- function(n, sims) {
    rerun(n, mean(sample(sims, replace = TRUE))) %>%
      flatten_dbl()
  }
  samples_boot <- samples %>% 
    mutate(
      medias_boot_30_1 = map(sims, ~means_boot(n = 30, .)), 
      medias_boot_30_2 = map(sims, ~means_boot(n = 30, .)), 
      medias_boot_1000_1 = map(sims, ~means_boot(n = 1000, .)), 
      medias_boot_1000_2 = map(sims, ~means_boot(n = 1000, .))
    )

  emp_dists <- samples_boot %>% 
    unnest(cols = sims) %>% 
    rename(obs = sims)
  emp_dists_plots <- ggplot(emp_dists, aes(x = obs)) +
    geom_histogram(binwidth = 2, alpha = 0.5, fill = "darkgray") +
    geom_vline(aes(color = "mu", xintercept = 5), alpha = 0.5, 
               show.legend = FALSE) +
    geom_vline(aes(xintercept = x_bar, color = "x_bar"), show.legend = FALSE, 
               alpha = 0.8, linetype = "dashed") +
    xlim(-15, 20) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    labs(x = "", y = "", subtitle = expression("Distribución empírica"~P[n])) +
    scale_colour_manual(values = c('mu' = 'red', 'x_bar' = 'blue'), name = '', 
                        labels = c(expression(mu), expression(bar(x)))) +
    facet_wrap(~ sample, ncol = 1) +
    theme(strip.background = element_blank(), strip.text.x = element_blank(), 
          axis.text.y = element_blank())

  boot_dists_30 <- samples_boot %>% 
    unnest(cols = c(medias_boot_30_1, medias_boot_30_2)) %>% 
    pivot_longer(cols = c(medias_boot_30_1, medias_boot_30_2), 
                 values_to = "mu_hat_star", names_to = "boot_trial",
                 names_prefix = "medias_boot_30_")
  boot_dists_30_plot <- ggplot(boot_dists_30, aes(x = mu_hat_star)) +
    geom_histogram(alpha = 0.5, fill = "darkgray") +
    labs(x = "", y = "",
         subtitle = expression("Distribución bootstrap B = 30")) +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_vline(aes(xintercept = x_bar), color = "blue", 
               linetype = "dashed", alpha = 0.8) +
    facet_grid(sample~boot_trial) +
    theme(strip.background = element_blank(), strip.text.y = element_blank(), 
          axis.text.y = element_blank())

  boot_dists_1000 <- samples_boot %>% 
    unnest(cols = c(medias_boot_1000_1, medias_boot_1000_2)) %>% 
    pivot_longer(cols = c(medias_boot_1000_1, medias_boot_1000_2), 
                 values_to = "mu_hat_star", names_to = "boot_trial",
                 names_prefix = "medias_boot_1000_")
  boot_dists_1000_plot <- ggplot(boot_dists_1000, aes(x = mu_hat_star)) +
    geom_histogram(alpha = 0.5, fill = "darkgray") +
    labs(subtitle = expression("Distribución bootstrap B = 1000"), 
         x = "", y = "") +
    geom_vline(xintercept = 5, color = "red", alpha = 0.5) +
    geom_vline(aes(xintercept = x_bar), color = "blue", 
               linetype = "dashed", alpha = 0.8) +
    facet_grid(sample~boot_trial) +
    scale_colour_manual(values = c('mu' = 'red', 'x_bar' = 'blue'), name = '',
                        labels = c(expression(mu), expression(bar(x)))) +
    theme(strip.background = element_blank(), strip.text.y = element_blank(), 
          strip.text.x = element_blank(), axis.text.y = element_blank())

  (pob_plot | plot_spacer() | plot_spacer()) /
    (emp_dists_plots | boot_dists_30_plot | boot_dists_1000_plot) +
    plot_layout(heights = c(1, 5), "cm")
#+end_src

#+REVEAL: split
En la siguiente gráfica mostramos 6 posibles muestras de tamaño 50 simuladas de
la población, para cada una de ellas se graficó la distribución empírica y se
se realizan histogramas de la distribución bootstrap con $B=30$ y $B=1000$, en 
cada caso hacemos dos repeticiones, notemos que cuando el número de muestras 
bootstrap es grande las distribuciones bootstrap son muy similares (para una 
muestra de la población dada), esto es porque disminuimos el erro Monte Carlo. 
También vale la pena recalcar que la distribución bootstrap está centrada en el 
valor observado en la muestra (línea azúl punteada) y no en el valor poblacional
sin embargo la forma de la distribución es similar a lo largo de las filas.

#+REVEAL: split
#+attr_html: :width 1200 :align center
file:images/bootstrap_mc_error.png

#+REVEAL: split
Entonces, ¿cuántas muestras bootstrap? 

1. Incluso un número chico de replicaciones bootstrap, digamos $B=25$ es
   informativo, y $B=50$ con frecuencia es suficiente para dar una buena
   estimación de $\mathsf{ee}_P(\hat{\theta})$ (citep:Efron1993).

2. Cuando se busca estimar error estándar (citep:Chihara2018) recomienda $B=1000$
   muestras, o $B=10,000$ muestras dependiendo la precisión que se busque.

* /Boostrap/ y otras estadísticas 


El /bootstrap/ es una técnica versátil. Un ejemplo son *estimadores de razón*, que
tienen la forma
\begin{align}
\hat{r} = \frac{\overline y}{\overline x}\,.
\end{align}

Por ejemplo, ¿cómo haríamos estimación para el procentaje de área area habitable
de las casas en relación al tamaño del lote? Una manera de estimar esta cantidad
es dividiendo la suma del área habitable de nuestra muestra y dividirlo entre
la suma del área de los lotes de nuestra muestra, como en la fórmula anterior. Esta
fórmula es más difícil pues tanto numerador como denominador tienen variabilidad,
y estas dos cantidades no varían independientemente.

Con el /bootstrap/ podemos atacar estos problemas.

** Estimadores de razón

Nuestra muestra original es:

#+begin_src R :exports both :results org 
  set.seed(250)
  casas_muestra <- sample_n(poblacion_casas, 200)
  casas_muestra |> as.data.frame() |> str()
#+end_src

#+RESULTS:
#+begin_src org
'data.frame':	200 obs. of  46 variables:
 $ id                   : num  1166 855 579 1158 882 ...
 $ tipo_zona            : chr  "RL" "RL" "FV" "RL" ...
 $ frente_lote          : num  79 102 34 34 44 81 70 78 64 61 ...
 $ calle                : chr  "Pave" "Pave" "Pave" "Pave" ...
 $ forma_lote           : chr  "IR1" "Reg" "Reg" "IR1" ...
 $ nombre_zona          : chr  "NridgHt" "Sawyer" "Somerst" "NridgHt" ...
 $ tipo_edificio        : chr  "1Fam" "1Fam" "TwnhsE" "Twnhs" ...
 $ estilo               : chr  "1Story" "1Story" "2Story" "1Story" ...
 $ calidad_gral         : num  7 5 7 7 7 6 5 6 6 5 ...
 $ condicion_gral       : num  5 4 5 5 5 5 5 6 5 7 ...
 $ año_construccion     : num  2009 1955 2007 2007 1990 ...
 $ calidad_exteriores   : chr  "Gd" "TA" "Gd" "Gd" ...
 $ material_exteriores  : chr  "VinylSd" "Wd Sdng" "VinylSd" "VinylSd" ...
 $ condicion_exteriores : chr  "TA" "TA" "TA" "TA" ...
 $ calidad_sotano       : chr  "Gd" "TA" "Gd" "Gd" ...
 $ condicion_sotano     : chr  "TA" "TA" "TA" "TA" ...
 $ tipo_sotano          : chr  "Unf" "ALQ" "Unf" "GLQ" ...
 $ calefaccion          : chr  "GasA" "GasA" "GasA" "GasA" ...
 $ calidad_calefaccion  : chr  "Ex" "TA" "Ex" "Ex" ...
 $ aire_acondicionado   : chr  "Y" "Y" "Y" "Y" ...
 $ baños_completos      : num  2 1 2 2 2 1 1 2 2 2 ...
 $ baños_medios         : num  0 1 0 0 1 0 0 0 1 0 ...
 $ recamaras_sup        : num  3 3 2 2 3 3 3 3 3 3 ...
 $ calidad_cocina       : chr  "Gd" "TA" "Gd" "Gd" ...
 $ cuartos_sup          : num  7 6 5 6 7 5 6 7 7 5 ...
 $ tipo_garage          : chr  "Attchd" "Attchd" "Detchd" "Attchd" ...
 $ terminado_garage     : chr  "RFn" "Unf" "Unf" "RFn" ...
 $ num_coches           : num  2 2 2 2 2 0 0 2 2 2 ...
 $ calidad_garage       : chr  "TA" "TA" "TA" "TA" ...
 $ condicion_garage     : chr  "TA" "TA" "TA" "TA" ...
 $ año_venta            : num  2009 2006 2008 2009 2007 ...
 $ mes_venta            : num  9 7 2 7 4 5 12 6 2 9 ...
 $ tipo_venta           : chr  "New" "WD" "WD" "WD" ...
 $ condicion_venta      : chr  "Partial" "Abnorml" "Abnorml" "Normal" ...
 $ lat                  : num  42.1 42 42.1 42.1 42 ...
 $ long                 : num  -93.7 -93.7 -93.6 -93.7 -93.6 ...
 $ area_sotano_m2       : num  140 164 64 122 107 ...
 $ area_1er_piso_m2     : num  139.5 165.3 65.3 122.1 110.3 ...
 $ area_2o_piso_m2      : num  0 0 64 0 49.2 ...
 $ area_habitable_sup_m2: num  140 165 129 122 160 ...
 $ area_garage_m2       : num  59.8 42.2 50.2 58.2 37.2 ...
 $ area_lote_m2         : num  886 1665 335 465 1278 ...
 $ precio_miles         : num  233 170 146 230 188 ...
 $ valor_misc_miles     : num  0 0 0 0 0 0 0 0 0 0 ...
 $ precio_m2_miles      : num  1.67 1.03 1.13 1.88 1.18 ...
 $ precio_m2            : num  1671 1029 1129 1884 1175 ...
#+end_src

#+REVEAL: split
El estimador de interés es:

#+begin_src R :exports code :results none 
  estimador_razon <- function(split, ...){
    muestra <- analysis(split)
    muestra |>
      summarise(estimate = sum(area_habitable_sup_m2) / sum(area_lote_m2),
                .groups = "drop") |>
      mutate(term = "area del lote construida")
  }
#+end_src

#+REVEAL: split
Y nuestra estimación puntual es

#+begin_src R :exports both :results org 
  estimador <- casas_muestra |>
    summarise(estimate = sum(area_habitable_sup_m2) / sum(area_lote_m2))
  estimador
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 1
  estimate
     <dbl>
1    0.141
#+end_src

Es decir que en promedio, un poco menos del $15\%$ del lote total es ocupado por área habitable. 
Ahora hacemos bootstrap para construir un intervalo:

#+REVEAL: split
#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-bootstrap-razon.jpeg :exports results :results output graphics file
  library(rsample)
  dist_boot <- bootstraps(casas_muestra,  2000) |>
    mutate(res_boot = map(splits, estimador_razon)) 
  g_1 <- ggplot(dist_boot %>% unnest(res_boot), aes(x = estimate)) +
    geom_histogram(bins = 20) + sin_lineas
  g_2 <- ggplot(dist_boot %>% unnest(res_boot), aes(sample = estimate)) +
    geom_qq() + geom_qq_line(colour = 'red') + sin_lineas
  g_1 + g_2
#+end_src

#+RESULTS:
[[file:../images/casas-bootstrap-razon.jpeg]]

#+REVEAL: split
En este caso la cola derecha parece tener menos dispersión que una distribución normal.
Usamos un intervalo de percentiles para obtener:

#+begin_src R :exports both :results org 
  dist_boot |> int_pctl(res_boot) |>
    mutate(estimador = estimador$estimate) |>
    rename(media_boot = .estimate) |>
    mutate(sesgo = media_boot - estimador) |>
    select(-.method, -term)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 6
  .lower media_boot .upper .alpha estimador   sesgo
   <dbl>      <dbl>  <dbl>  <dbl>     <dbl>   <dbl>
1  0.121      0.142  0.159   0.05     0.141 0.00101
#+end_src


#+REVEAL: split
Nótese que el sesgo es bajo.  De modo que en esta zona, entre $12\%$ y $16\%$ de toda
el área disponible es ocupada por área habitable: estas son casas que tienen
jardines o terrenos, garage relativamente grandes.

** Suavizadores

Podemos usar el /bootstrap/ para juzgar la variabilidad de un suavizador, que
consideramos como nuestra estadística:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-suavizador.jpeg :exports results :results output graphics file
  graf_casas <- function(data){
    ggplot(data %>% filter(calidad_gral < 7), 
           aes(x = area_habitable_sup_m2)) + 
      geom_point(aes(y = precio_m2_miles), alpha = 0.75) +
      geom_smooth(aes(y = precio_m2_miles), method = "loess", span = 0.7, 
                  se = FALSE, method.args = list(degree = 1, family = "symmetric")) +
      sin_lineas 
  }
  graf_casas(casas_muestra)
#+end_src

#+RESULTS:
[[file:../images/casas-suavizador.jpeg]]

#+REVEAL: split
Podemos hacer bootstrap para juzgar la estabilidad del suavizador:

#+begin_src R :exports none :results none
  suaviza_boot <- function(x, data){
    ## remuestreo
    muestra_boot <- sample_n(data, nrow(data), replace = T)
    ajuste <- loess(precio_m2_miles ~ area_habitable_sup_m2, data = muestra_boot, 
                    degree = 1, span = 0.7, family = "symmetric")
    datos_grafica <- tibble(area_habitable_sup_m2 = seq(25, 250, 5))
    ajustados <- predict(ajuste, newdata = datos_grafica)
    datos_grafica %>% mutate(ajustados = ajustados) %>% 
      mutate(rep = x)
  }
  reps <- map(1:10, ~ suaviza_boot(.x, casas_muestra %>% filter(calidad_gral < 7))) %>% 
    bind_rows()
#+end_src

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-suavizador-bs.jpeg :exports results :results output graphics file
  ## ojo: la rutina loess no tienen soporte para extrapolación
  graf_casas(casas_muestra) + 
    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 1, colour = "red") +
    coord_cartesian(xlim = c(50, 225))
#+end_src

#+RESULTS:
[[file:../images/casas-suavizador-bs.jpeg]]

#+REVEAL: split
Donde vemos que algunas cambios de pendiente del suavizador original no son muy
interpretables (por ejemplo, para áreas chicas) y alta variabilidad en general
en los extremos. Podemos hacer más iteraciones para calcular bandas de
confianza:

#+HEADER: :width 1200 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/casas-suavizador-bandas.jpeg :exports results :results output graphics file
  reps <- map(1:200, ~ suaviza_boot(.x, casas_muestra %>% filter(calidad_gral < 7))) %>% 
    bind_rows()
  ## ojo: la rutina loess no tienen soporte para extrapolación
  graf_casas(casas_muestra) + 
    geom_line(data = reps, aes(y = ajustados, group = rep), alpha = 0.2, colour = "red") +
    coord_cartesian(xlim = c(50, 225))
#+end_src

#+RESULTS:
[[file:../images/casas-suavizador-bandas.jpeg]]

#+REVEAL: split
Donde observamos cómo tenemos incertidumbre en cuanto al nivel y forma de las
curvas en los extremos de los datos (casas grandes y chicas), lo cual es
natural. Aunque podemos resumir para hacer bandas de confianza, mostrar
remuestras de esta manera es informativo: por ejempo: vemos cómo es probable
también que para casas de emnos de 70 metros cuadrados el precio por metro
cuadrado no cambia tanto (líneas constantes). 

bibliographystyle:abbrvnat
bibliography:references.bib


* TODO /Jacknife/ y cuantificación de sesgo

* TODO Generalización intervalos de confianza

* Temas por ver                                                    :noexport:

- Jacknife (sesgo, reducción de sesgo)
- Pruebas de permutación (pruebas estadisticas exactas)
- Validación cruzada
